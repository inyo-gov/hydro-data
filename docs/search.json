[
  {
    "objectID": "package/doc/hydro-data-website.html",
    "href": "package/doc/hydro-data-website.html",
    "title": "Hydro Data website",
    "section": "",
    "text": "This vignette links to the published Hydro Data reports (depth-to-water and flow/pumping) hosted on GitHub Pages. It also documents how the reports are generated from the Quarto sources and shows example access patterns for each data type in the package manifest."
  },
  {
    "objectID": "package/doc/hydro-data-website.html#reports",
    "href": "package/doc/hydro-data-website.html#reports",
    "title": "Hydro Data website",
    "section": "Reports",
    "text": "Reports\n\nDepth-to-water (DTW): https://inyo-gov.github.io/hydro-data/\nFlow and pumping: https://inyo-gov.github.io/hydro-data/flow.html"
  },
  {
    "objectID": "package/doc/hydro-data-website.html#source-documents",
    "href": "package/doc/hydro-data-website.html#source-documents",
    "title": "Hydro Data website",
    "section": "Source documents",
    "text": "Source documents\n\nDTW report source: index.qmd\nFlow report source: flow.qmd"
  },
  {
    "objectID": "package/doc/hydro-data-website.html#example-data-access",
    "href": "package/doc/hydro-data-website.html#example-data-access",
    "title": "Hydro Data website",
    "section": "Example data access",
    "text": "Example data access\nThese examples use the manifest to fetch the published datasets and read them into R. They mirror the data types used by index.qmd (DTW/monitoring wells) and flow.qmd (flow and production).\nlibrary(hydrodata)\n\nMonitoring wells master (DTW reporting base)\nmw_path &lt;- hydrodata_fetch(\"monitoring_wells_master\", year = \"2025\")\nmw &lt;- read.csv(mw_path, stringsAsFactors = FALSE)\nhead(mw)\n\n\nSingle-year monitoring wells export (test well WY file)\ntestwell_path &lt;- hydrodata_fetch(\"testwellwy\", year = \"2025\")\ntestwell &lt;- read.csv(testwell_path, stringsAsFactors = FALSE)\nhead(testwell)\n\n\nTotals and means through September (flow/pumping base table)\ntotals_path &lt;- hydrodata_fetch(\"totals_means\", year = \"2025\")\ntotals_means &lt;- read.csv(totals_path, stringsAsFactors = FALSE)\nhead(totals_means)\n\n\nOVGA surface-water flow import\nflow_path &lt;- hydrodata_fetch(\"ovga_swflow\", year = \"2025\")\novga_flow &lt;- read.csv(flow_path, stringsAsFactors = FALSE)\nhead(ovga_flow)\n\n\nOVGA production import\nprod_path &lt;- hydrodata_fetch(\"ovga_production\", year = \"2025\")\novga_production &lt;- read.csv(prod_path, stringsAsFactors = FALSE)\nhead(ovga_production)\n\n\nOVGA DTW import\ndtw_path &lt;- hydrodata_fetch(\"ovga_dtw\", year = \"2025\")\novga_dtw &lt;- read.csv(dtw_path, stringsAsFactors = FALSE)\nhead(ovga_dtw)"
  },
  {
    "objectID": "package/doc/hydro-data-website.html#rebuild-the-website-locally",
    "href": "package/doc/hydro-data-website.html#rebuild-the-website-locally",
    "title": "Hydro Data website",
    "section": "Rebuild the website locally",
    "text": "Rebuild the website locally\nsystem(\"quarto render index.qmd\")\nsystem(\"quarto render flow.qmd\")\nIf you want the full site build:\nsystem(\"quarto render\")"
  },
  {
    "objectID": "package/vignettes/hydro-data-website.html",
    "href": "package/vignettes/hydro-data-website.html",
    "title": "Hydro Data annual update",
    "section": "",
    "text": "This vignette is the annual update walkthrough for the Hydro Data reports (depth-to-water and flow/pumping). It links to the published reports, explains how to reproduce them from the Quarto sources, and shows example access patterns for each data type listed in the package manifest."
  },
  {
    "objectID": "package/vignettes/hydro-data-website.html#reports-published",
    "href": "package/vignettes/hydro-data-website.html#reports-published",
    "title": "Hydro Data annual update",
    "section": "Reports (published)",
    "text": "Reports (published)\n\nDepth-to-water (DTW): https://inyo-gov.github.io/hydro-data/\nFlow and pumping: https://inyo-gov.github.io/hydro-data/flow.html"
  },
  {
    "objectID": "package/vignettes/hydro-data-website.html#source-documents-authoritative",
    "href": "package/vignettes/hydro-data-website.html#source-documents-authoritative",
    "title": "Hydro Data annual update",
    "section": "Source documents (authoritative)",
    "text": "Source documents (authoritative)\n\nDTW report source: index.qmd\nFlow report source: flow.qmd"
  },
  {
    "objectID": "package/vignettes/hydro-data-website.html#annual-update-workflow",
    "href": "package/vignettes/hydro-data-website.html#annual-update-workflow",
    "title": "Hydro Data annual update",
    "section": "Annual update workflow",
    "text": "Annual update workflow\nEach package version targets a fixed data release via the manifest URLs. That means the report outputs are reproducible for that version because the source files resolve to the same release assets every time.\nRecommended steps for an annual update:\n\nUpdate the release assets for the new water year.\nRefresh inst/extdata/manifest.csv with the new release URLs and checksums.\nRun the reports from the Quarto sources (index.qmd, flow.qmd).\nPublish the site."
  },
  {
    "objectID": "package/vignettes/hydro-data-website.html#example-data-access",
    "href": "package/vignettes/hydro-data-website.html#example-data-access",
    "title": "Hydro Data annual update",
    "section": "Example data access",
    "text": "Example data access\nThese examples use the manifest to fetch the published datasets and read them into R. They mirror the data types used by index.qmd (DTW/monitoring wells) and flow.qmd (flow and production).\nlibrary(hydrodata)\n\nMonitoring wells master (DTW reporting base)\nmw_path &lt;- hydrodata_fetch(\"monitoring_wells_master\", year = \"2025\")\nmw &lt;- read.csv(mw_path, stringsAsFactors = FALSE)\nhead(mw)\n\n\nSingle-year monitoring wells export (test well WY file)\ntestwell_path &lt;- hydrodata_fetch(\"testwellwy\", year = \"2025\")\ntestwell &lt;- read.csv(testwell_path, stringsAsFactors = FALSE)\nhead(testwell)\n\n\nTotals and means through September (flow/pumping base table)\ntotals_path &lt;- hydrodata_fetch(\"totals_means\", year = \"2025\")\ntotals_means &lt;- read.csv(totals_path, stringsAsFactors = FALSE)\nhead(totals_means)\n\n\nOVGA surface-water flow import\nflow_path &lt;- hydrodata_fetch(\"ovga_swflow\", year = \"2025\")\novga_flow &lt;- read.csv(flow_path, stringsAsFactors = FALSE)\nhead(ovga_flow)\n\n\nOVGA production import\nprod_path &lt;- hydrodata_fetch(\"ovga_production\", year = \"2025\")\novga_production &lt;- read.csv(prod_path, stringsAsFactors = FALSE)\nhead(ovga_production)\n\n\nOVGA DTW import\ndtw_path &lt;- hydrodata_fetch(\"ovga_dtw\", year = \"2025\")\novga_dtw &lt;- read.csv(dtw_path, stringsAsFactors = FALSE)\nhead(ovga_dtw)"
  },
  {
    "objectID": "package/vignettes/hydro-data-website.html#rebuild-the-reports-locally",
    "href": "package/vignettes/hydro-data-website.html#rebuild-the-reports-locally",
    "title": "Hydro Data annual update",
    "section": "Rebuild the reports locally",
    "text": "Rebuild the reports locally\nsystem(\"quarto render index.qmd\")\nsystem(\"quarto render flow.qmd\")\nIf you want the full site build:\nsystem(\"quarto render\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Flow Data",
    "section": "",
    "text": "This report walks through a real-world data workflow: we take depth-to-water (DTW) observations from monitoring wells, clean and combine them in R, and prepare files for upload to a database. Think of it as a guided lab where each section does one job—load data, join tables, filter bad values, then export.\nWe use two terms throughout: station identification (staid) for the unique well or sensor ID, and reference point elevation (RP elevation) for the fixed elevation from which depth is measured. Data are delivered as ZRXP text files; we parse them, average to one value per station per day, then keep only rows that have a valid reference point elevation and that match our list of approved stations (OVGA). What you get at the end is an annual update file, a full master table, and upload-ready CSVs plus a few checks and plots so we can spot problems before import.\nFor a new water year, change the year in three places: input paths and master, ICWD output file names, and OVGA upload. The full R and report source is in index.qmd.\nAnnual update instructions: See ANNUAL_UPDATE_GUIDE.md for comprehensive step-by-step instructions on updating this workflow for the next water year."
  },
  {
    "objectID": "index.html#raw-input-coverage",
    "href": "index.html#raw-input-coverage",
    "title": "Flow Data",
    "section": "Raw input coverage",
    "text": "Raw input coverage\nThe table below provides a quick inventory of each input file: record counts, unique monitoring points, and the raw date range. Use this to verify that the received transfer packet aligns with expectations before moving on to joins, aggregation, and exports.\n\n\n\n\n\n\n\n\n\n\n\nFile\nRecords\nUnique_staids\nDate_start\nDate_end\n\n\n\nDepthRP_2024-25.dat\n82831\n743\n2024-10-01\n2025-09-30\n\n\nDepthGE_2024-25.dat\n74670\n655\n2024-10-01\n2025-09-30\n\n\nOwensValley_DepthWSE_2024-25.dat\n86968\n383\n2024-10-01\n2025-09-30\n\n\n\n\n\n\n\n\n\nEach file repeats headers for each monitoring well. Extract the well ID from #TSPATH and join to observation rows (lines that do not start with #). The example shows the header block followed by timestamped values."
  },
  {
    "objectID": "index.html#monitoring-points-map-static",
    "href": "index.html#monitoring-points-map-static",
    "title": "Depth to water - annual water year updates",
    "section": "Monitoring points map (static)",
    "text": "Monitoring points map (static)\nThe map below shows monitoring points with valid coordinates, filtered to public sites in the Owens Valley.\n\n\n\n\nOwens Valley monitoring points.\n\n\n\n\nparse depthGE.datdat_content &lt;- readLines(file_pathGE)\n\n# Initialize variables to store data\ndata_list &lt;- list()\n\n# Function to check if a line contains timestamp and value\nis_data_line &lt;- function(line) {\n  grepl(\"\\\\d+ \\\\d+\\\\.\\\\d+\", line)\n}\n\n# Loop through each line in the file\nfor (line in dat_content) {\n  # Check if the line starts with '#TSPATH'\n  if (startsWith(line, \"#TSPATH\")) {\n    # Extract 'staid' from the '#TSPATH' line\n    staid &lt;- sub('.*/([TVFRSW]\\\\w+).*', '\\\\1', line)\n  }\n  \n  # Check if the line does not start with '#' and contains timestamp and value\n  if (!startsWith(line, \"#\") && is_data_line(line) && !is.na(staid)) {\n    # If the line does not start with '#' and contains timestamp and value,\n    # add data to the list directly\n    data_list &lt;- c(data_list, list(data.frame(staid, dateread = line)))\n  }\n}\n\n# Combine the data frames in the list into a single data frame\ndata_df &lt;- bind_rows(data_list)\n\n# Remove rows with NA values, Remove 'row' and 'value' columns\ndepthGE &lt;- na.omit(data_df) %&gt;% select(staid, dateread)\n\n#separate the data column and assign numeric class to dtw\ndepthGE &lt;- depthGE %&gt;% separate(dateread, c(\"date\", \"dtw.bgs\"),sep = \" \") \ndepthGE$dtw.bgs &lt;- as.numeric(depthGE$dtw.bgs)\n# head(depthGE)\n\nsaveRDS(depthGE, file = here('data','hydro','2025','depthGE.RDS'))\n\n# notes: sub('.*/([TVFRSW]\\\\w+).*', '\\\\1', line) extracts the staid from the #TSPATH line.\n\n\n\ntestwellupdate# rename the columns\n# clean up the date with formal date specification\ntestwell.up &lt;- try %&gt;% select(-date, -datetime) %&gt;% rename(date = date.y.m.d) %&gt;% mutate(source = \"DWP\")  \n# head(testwell.up)\n\n\n\nappend updates to master database## Append updates to master\ntestwells.combined &lt;- bind_rows(hist, testwell.up) \n\n# head(testwells.combined)\n# 1,145,360 records going back to 1971\n\n# testwells.combined %&gt;% n_distinct(staid)\n# testwells.combined %&gt;% distinct(staid) %&gt;% nrow()\n\n\n\n\n\n\nMetric\nValue\n\n\n\nAnnual update rows\n89,289\n\n\nAnnual update staids\n750\n\n\nActive database rows\n1,324,540\n\n\nActive database staids\n1,381"
  },
  {
    "objectID": "index.html#masterdb",
    "href": "index.html#masterdb",
    "title": "Flow Data",
    "section": "ICWD database exports",
    "text": "ICWD database exports\n2023 water year\n\nCompleted 1-24-24 annual update (testwellwy2023.csv)\nCompleted 1-24-24 full database (Monitoring_Wells_Master_2023.csv)\n2024 water year\n\nCompleted 12-10-24 annual update (testwellwy2024.csv)\nCompleted 12-10-24 full database (Monitoring_Wells_Master_2024.csv)\n2025 water year\n\nCompleted 1-26-26 annual update (testwellwy2025.csv)\nCompleted 1-26-26 raw annual update (testwellwy2025_raw.csv)\nCompleted 1-26-26 full database (Monitoring_Wells_Master_2025.csv)\n\ntestwellwy2025.csv is the WY2025 daily slice (one row per station per day). testwellwy2025_raw.csv keeps every read before daily averaging, for archive or troubleshooting.\n\nsave master database updatesout_icwd &lt;- here(\"output\", \"2025wy\", \"ICWD\")\ndir.create(out_icwd, recursive = TRUE, showWarnings = FALSE)\n\n# single year\ntestwell.up %&gt;% write_csv(file.path(out_icwd, \"testwellwy2025.csv\"))\n\n# full-resolution annual update (pre-daily aggregation)\nraw_update &lt;- try %&gt;%\n  select(staid, datetime, dtw.rp, dtw.bgs, wse)\nraw_update %&gt;% write_csv(file.path(out_icwd, \"testwellwy2025_raw.csv\"))\n\n# whole dataset\ntestwells.combined %&gt;% write_csv(file.path(out_icwd, \"Monitoring_Wells_Master_2025.csv\"))\n\n#"
  },
  {
    "objectID": "index.html#reference-point-elevation-integration",
    "href": "index.html#reference-point-elevation-integration",
    "title": "Flow Data",
    "section": "Reference point elevation integration",
    "text": "Reference point elevation integration\nDepth-to-water is measured from a fixed mark at each well—the reference point elevation (RP elevation). We need that value to interpret the depth numbers. In this section we attach the most recent reference point elevation to each station id(entification) (staid) and flag any stations where it’s missing.\nStations without a reference point elevation stay in our internal tables but are left out of the OVGA upload so we don’t import incomplete records. We still keep the data for later if RP values are added.\nFirst we convert the RP dates into a standard format so we can join them to the annual update.\n\nconvert RP dates## RP can be continually changing so need to be recursive with the RP file for updates.\n\n# date conversion\nrpelev_date &lt;- rpelev %&gt;% \n  mutate(date = lubridate::mdy(date_c))\n\nhead(rpelev_date) %&gt;%\n  datatable(options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE))\n\n\n\n\n\nNext, we identify the most recent reference point elevation per staid. That way each monitoring point uses the latest available reference point during the update.\n\n\n\n\n\n\nWe then attach that most recent reference point elevation to each staid so every row has a reference point value for the join.\n\n\n\n\n\n\nWe join RP elevations to the annual update so DTW values can be expressed relative to the reference point. This join also supports QA/QC checks for missing RP data.\n\n\n  count_unique_staids\n1                 750\n\n\nAfter the reference-point join we average to one value per station per day. OVGA accepts no more than one value per station per day, so this daily aggregation is required for the OVGA import. For staids with many readings per day we take the mean; that also keeps the table smaller and every staid on the same time step.\n\n\n\n\n\n\nThe tables and plots below summarize measurement frequency and daily aggregation behavior, which is used to validate that the daily rollup is behaving as expected.\n\n\n\n\n\n\n\n\n\n\n# A tibble: 10,079 × 4\n# Groups:   staid [750]\n   staid date       daily_count daily_count_category\n   &lt;chr&gt; &lt;date&gt;           &lt;int&gt; &lt;fct&gt;               \n 1 V271  2024-10-01          96 (50,100]            \n 2 V271  2024-10-02          96 (50,100]            \n 3 V271  2024-10-03          96 (50,100]            \n 4 V271  2024-10-04          96 (50,100]            \n 5 V271  2024-10-05          96 (50,100]            \n 6 V271  2024-10-06          96 (50,100]            \n 7 V271  2024-10-07          96 (50,100]            \n 8 V271  2024-10-08          96 (50,100]            \n 9 V271  2024-10-09          96 (50,100]            \n10 V271  2024-10-10          96 (50,100]            \n# ℹ 10,069 more rows\n\n\n\n\n# A tibble: 10 × 2\n   daily_count_category count_unique_staids\n   &lt;fct&gt;                              &lt;int&gt;\n 1 [0,1]                                749\n 2 (1,2]                                 21\n 3 (2,3]                                  4\n 4 (3,4]                                  5\n 5 (4,5]                                  5\n 6 (5,10]                                 6\n 7 (10,15]                                3\n 8 (15,20]                                6\n 9 (20,50]                               10\n10 (50,100]                               1\n\n\n\n\n      .\n1 [0,1]\n\n\nWY2025 update: 33 out of 750 staids have multiple measurements per day (some hourly and a few up to 15‑minute intervals). 32 of those 33 staids also have single‑measurement days.\nWe harmonize these to daily values to reduce data size and make the annual update consistent across measurement frequencies. The next steps show how we aggregate to daily means and then summarize record frequency by water year to confirm that high-frequency sensors are behaving as expected.\n\n\n\n\n\n\nThe distributions below provide a QA/QC snapshot of record counts per staid. A small subset of sites should show high counts (automated sensors), while most sites should fall in the low-frequency bins (manual measurements).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDaily averaging collapses multiple measurements on the same day to a single value per staid and day. This daily series is the basis for annual summaries and export preparation.\n\navg daily dtw - aggregating# daily average dtw\ndtwrpavg.rpelev &lt;- dtwrp.rpelev %&gt;% \n  group_by(staid, date, rp_elev) %&gt;% \n  summarise(dtw.rp =  round(mean(dtw.rp),2))\n\n\n# dtwrpavg.rpelevBeta &lt;- dtwrp.rpelev %&gt;% group_by(staid, date, rp_elev) %&gt;% summarise(dtw.rp =  round(mean(dtw.rp),2),\n#           dailyCount = n()\n#           ) %&gt;% arrange(desc(dailyCount))\ndtwrpavg.rpelev\n\n# A tibble: 10,079 × 4\n# Groups:   staid, date [10,079]\n   staid date       rp_elev dtw.rp\n   &lt;chr&gt; &lt;date&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 F033  2024-10-10   3834.   4.56\n 2 F033  2024-11-07   3834.   4.56\n 3 F033  2024-12-05   3834.   4.56\n 4 F033  2025-01-08   3834.   4.56\n 5 F033  2025-03-10   3834.   4.56\n 6 F033  2025-04-14   3834.   4.56\n 7 F033  2025-06-09   3834.   4.56\n 8 F033  2025-07-11   3834.   4.56\n 9 F033  2025-08-06   3834.   4.56\n10 F033  2025-09-04   3834.   4.56\n# ℹ 10,069 more rows\n\navg daily dtw - aggregating# datatable(dtwrpavg.rpelev,\n  # caption = 'daily averaging reduces data')\n\n\nWe also infer a measurement method flag based on measurement frequency so that OVGA export metadata stays consistent when explicit method values are not provided with the raw data.\n\nassign TR vs ES method based on measurement frequency# More than 4 reads per month (48 per year) indicates pressure transducer (TR);\n# fewer indicates electric sounder (ES).\n\nrecord.number &lt;- dtwrp.rpelev %&gt;% \n  filter(!is.na(rp_elev)) %&gt;% \n  group_by(staid) %&gt;% \n  summarise(count.with.rpe = n()) %&gt;% \n  mutate(MMethod = case_when(count.with.rpe &gt;= 48 ~ \"TR\",\n                            count.with.rpe &lt; 48~ \"ES\"))\n# if there are four reads per day, once per month, approximates to 48. quick and dirty separation. a list of pressure transducer staids would be better if it could be maintained.\n\nhead(record.number %&gt;% arrange(-count.with.rpe))\n\n# A tibble: 6 × 3\n  staid count.with.rpe MMethod\n  &lt;chr&gt;          &lt;int&gt; &lt;chr&gt;  \n1 V271            3190 TR     \n2 V202            1347 TR     \n3 T387            1346 TR     \n4 V251            1346 TR     \n5 T389            1239 TR     \n6 T438              17 ES     \n\n\n\nnumber of records per staid# records per staid\nLA.staids &lt;- dtwrpavg.rpelev %&gt;% group_by(staid) %&gt;% summarise(records = n())\n# head(LA.staids)\n# LA.staids %&gt;% arrange(desc(records))\n#785\n\n\nThe next QA/QC steps narrow the dataset to records eligible for OVGA import. We first identify staids that are present in the OVGA monitoring-point list, then quantify which of those lack RP elevations. Finally, we filter to records with valid RP elevations and OVGA-listed points before building the export template.\n\nstaids in data that are also on ovga listLA.staids.in.ovga &lt;- LA.staids %&gt;% semi_join(ovga_points, by = c(\"staid\"=\"mon_pt_name\"))\n\n# LA.staids.in.ovga %&gt;% nrow()\n#714\n\n\n\nmonitoring points missing rp elevations after join# monitoring points missing rp elevations after join\n# LA.staids.in.ovga\n# find how many staids are missing rp elevation\nna.rp.elev &lt;- dtwrpavg.rpelev %&gt;% \n  semi_join(LA.staids.in.ovga, by = 'staid') %&gt;% \n  filter(is.na(rp_elev)) %&gt;% \n  group_by(staid) %&gt;% \n  summarise(count.na = n())\n\n\n\nanti_join take NA rp elev off# anti_join removes records in x that match y\n# Select only data with rp elevations (not na)\nrpselect &lt;- dtwrpavg.rpelev %&gt;% anti_join(na.rp.elev, by = \"staid\")\n# rpselect\n# 19,793 1.24.2024\n\n\nFilter to records with RP elevation and valid OVGA monitoring points.\n\nsemi_join retain records in ovga staid list# 6,048 points including monitoring wells, pumping wells, surface water gauging stations.\n# semi_join returns records in x with a match in y\nrpselect2 &lt;- rpselect %&gt;% semi_join(ovga_points, by = c(\"staid\"=\"mon_pt_name\"))\n# head(rpselect2)\nrpselect2 %&gt;% arrange(staid,desc(date))\n\n# A tibble: 5,584 × 4\n# Groups:   staid, date [5,584]\n   staid date       rp_elev dtw.rp\n   &lt;chr&gt; &lt;date&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 F033  2025-09-04   3834.   4.56\n 2 F033  2025-08-06   3834.   4.56\n 3 F033  2025-07-11   3834.   4.56\n 4 F033  2025-06-09   3834.   4.56\n 5 F033  2025-04-14   3834.   4.56\n 6 F033  2025-03-10   3834.   4.56\n 7 F033  2025-01-08   3834.   4.56\n 8 F033  2024-12-05   3834.   4.56\n 9 F033  2024-11-07   3834.   4.56\n10 F033  2024-10-10   3834.   4.56\n# ℹ 5,574 more rows\n\nsemi_join retain records in ovga staid list# datatable(rpselect2)"
  },
  {
    "objectID": "index.html#ovgasave",
    "href": "index.html#ovgasave",
    "title": "Flow Data",
    "section": "OVGA template and export",
    "text": "OVGA template and export\nThe upload file for OVGA is built from the daily table after we drop rows that don’t belong: we keep only stations on the OVGA list, only rows that have a valid reference point elevation, and only depth values that pass our checks (not missing, not -777, not ≥ 500 ft). What’s left is a clean table that matches the OVGA import template.\nColumn names and order follow that template so the system can ingest the file without errors. The file is saved under output/2025wy/OVGA and used for the actual import.\n\ncreate ovga template# methodinfer %&gt;% distinct()\nmethodinfer &lt;- record.number %&gt;% select(-count.with.rpe)\n# %&gt;% distinct(staid)\n\nupload &lt;- rpselect2 %&gt;% \n  left_join(methodinfer, by = \"staid\") %&gt;% \n  # select(-latest_rp_date) %&gt;% \n  select(WellName = staid, \n         DateMeasured = date, \n         DepthToWater = dtw.rp, \n         ReferencePointElevation = rp_elev\n         ,\n         MMethod\n         ) %&gt;% \n  mutate(ReportingDate = \"\",\n         QAQCLevel = \"High\",\n         MeasMethod = MMethod,#\"ES\",# from join above\n         NoMeasFlag = \"\",\n         QuestMeasFlag = \"\",\n         DataSource = \"LADWP\",\n         CollectedBy = \"LADWP\",\n         UseInReporting = \"yes\",\n         Notes = \"\") %&gt;%\n  select(-MMethod) %&gt;%\n  filter(DepthToWater &lt; 500 & !is.na(DepthToWater) & DepthToWater != 'NA' & DepthToWater != -777 & ReferencePointElevation != 0) %&gt;%\n  select(WellName, DateMeasured, ReportingDate, DepthToWater, ReferencePointElevation, QAQCLevel, MeasMethod, NoMeasFlag, QuestMeasFlag, DataSource, CollectedBy, UseInReporting, Notes)\n\nupload \n\n# A tibble: 5,515 × 13\n# Groups:   WellName, DateMeasured [5,515]\n   WellName DateMeasured ReportingDate DepthToWater ReferencePointElevation\n   &lt;chr&gt;    &lt;date&gt;       &lt;chr&gt;                &lt;dbl&gt;                   &lt;dbl&gt;\n 1 F033     2024-10-10   \"\"                    4.56                   3834.\n 2 F033     2024-11-07   \"\"                    4.56                   3834.\n 3 F033     2024-12-05   \"\"                    4.56                   3834.\n 4 F033     2025-01-08   \"\"                    4.56                   3834.\n 5 F033     2025-03-10   \"\"                    4.56                   3834.\n 6 F033     2025-04-14   \"\"                    4.56                   3834.\n 7 F033     2025-06-09   \"\"                    4.56                   3834.\n 8 F033     2025-07-11   \"\"                    4.56                   3834.\n 9 F033     2025-08-06   \"\"                    4.56                   3834.\n10 F033     2025-09-04   \"\"                    4.56                   3834.\n# ℹ 5,505 more rows\n# ℹ 8 more variables: QAQCLevel &lt;chr&gt;, MeasMethod &lt;chr&gt;, NoMeasFlag &lt;chr&gt;,\n#   QuestMeasFlag &lt;chr&gt;, DataSource &lt;chr&gt;, CollectedBy &lt;chr&gt;,\n#   UseInReporting &lt;chr&gt;, Notes &lt;chr&gt;\n\n\n2023 water year (OVGA)\nCompleted 1-24-24\ncsv\n2024 water year (OVGA)\nCompleted 12-10-24\ncsv\n2025 water year (OVGA)\nCompleted 1-26-26\ncsv\n\n9329 well-days in update with rp elevations\n673 staids in update with rp elevations\n5584 well-days in update with rp elevations and in ovga list\n598 staids in update with rp elevations and in ovga list\n5515 well-days in the ovga upload\n590 staids in the ovga upload"
  },
  {
    "objectID": "index.html#ovgaupdate",
    "href": "index.html#ovgaupdate",
    "title": "Flow Data",
    "section": "OVGA export and comparison",
    "text": "OVGA export and comparison\nThe comparison below highlights year-over-year changes in which monitoring points are included in the OVGA DTW upload.\n\n\n\n\n\n\nReview this comparison after WY2025 processing to confirm which staids are missing and whether WSE-derived RP calculations are needed.\n\n\nRows: 12\nColumns: 11\n$ staid   &lt;chr&gt; \"T755\", \"T755\", \"T755\", \"T755\", \"T755\", \"T755\", \"T755\", \"T755\"…\n$ dtw.rp  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA\n$ wse     &lt;dbl&gt; 4208.76, 4208.51, 4208.51, 4208.28, 4208.51, 4208.51, 4208.28,…\n$ dtw.bgs &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA\n$ year    &lt;dbl&gt; 2024, 2024, 2024, 2025, 2025, 2025, 2025, 2025, 2025, 2025, 20…\n$ month   &lt;dbl&gt; 10, 11, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9\n$ day     &lt;int&gt; 22, 19, 9, 22, 12, 12, 16, 15, 16, 14, 18, 23\n$ hour    &lt;int&gt; 14, 13, 10, 10, 9, 9, 9, 14, 9, 10, 15, 13\n$ minute  &lt;int&gt; 2, 39, 40, 27, 27, 37, 46, 19, 51, 15, 17, 12\n$ date    &lt;date&gt; 2024-10-22, 2024-11-19, 2024-12-09, 2025-01-22, 2025-02-12, 20…\n$ source  &lt;chr&gt; \"DWP\", \"DWP\", \"DWP\", \"DWP\", \"DWP\", \"DWP\", \"DWP\", \"DWP\", \"DWP\",…\n\n\n\nsave OVGA import# OVGA Import Depth to Water: columns per schema (ReportingDate and UseInReporting optional; blank ReportingDate uses DateMeasured)\novga_dtw_cols &lt;- c(\"WellName\", \"DateMeasured\", \"ReportingDate\", \"DepthToWater\", \"ReferencePointElevation\", \"QAQCLevel\", \"MeasMethod\", \"NoMeasFlag\", \"QuestMeasFlag\", \"DataSource\", \"CollectedBy\", \"UseInReporting\", \"Notes\")\nwrite_ovga_dtw_csv &lt;- function(x, path) {\n  # Drop any staid/date so only OVGA-named columns (WellName, DateMeasured, ...) are written\n  x &lt;- x %&gt;% select(-any_of(c(\"staid\", \"date\"))) %&gt;% select(all_of(ovga_dtw_cols))\n  x[] &lt;- lapply(x, function(v) ifelse(is.na(v), \"\", as.character(v)))\n  write.table(x, path, sep = \",\", row.names = FALSE, quote = FALSE)\n}\n\nout_ovga &lt;- here(\"output\", \"2025wy\", \"OVGA\")\ndir.create(out_ovga, recursive = TRUE, showWarnings = FALSE)\nwrite_ovga_dtw_csv(upload, file.path(out_ovga, \"ovga_uploads_mw_with_rpe_102024_092025_zn.csv\"))\nwritexl::write_xlsx(upload %&gt;% select(-any_of(c(\"staid\", \"date\"))) %&gt;% select(all_of(ovga_dtw_cols)) %&gt;% mutate(across(everything(), ~replace(., is.na(.), \"\"))), file.path(out_ovga, \"ovga_uploads_mw_with_rpe_102024_092025_zn.xlsx\"))\n\n\n\ndatatablecol_w &lt;- list(\n  list(targets = 0:4, width = \"80px\"),\n  list(targets = 5, width = \"100px\"),\n  list(targets = 6:10, width = \"90px\")\n)\ndatatable(\n  upload,\n  caption = \"2024-2025 water year upload formatted for OVGA data management system.\",\n  options = list(\n    pageLength = 10,\n    lengthChange = TRUE,\n    scrollX = TRUE,\n    autoWidth = FALSE,\n    columnDefs = col_w\n  ),\n  class = \"compact stripe\"\n)\n\n\n\n\n\n\n\n\n\nMetric\nValue\n\n\n\nRows in OVGA upload\n5515\n\n\nUnique monitoring points\n590\n\n\nDate range\n2024-10-01 to 2025-09-30"
  },
  {
    "objectID": "index.html#ovga-dtw-exclusions-download",
    "href": "index.html#ovga-dtw-exclusions-download",
    "title": "Flow Data",
    "section": "OVGA DTW exclusions (download)",
    "text": "OVGA DTW exclusions (download)\nTable 1: Staids not in OVGA monitoring points list\nThese staids are excluded because they are not on the current OVGA monitoring points list. This list should be reviewed by the hydrologist and DB manager to decide which staids should be added to the OVGA monitoring points list on the backend.\n\n\n\n\n\n\nTable 2: Staids on OVGA list needing data quality resolution\nThese staids are on the OVGA monitoring points list but are excluded due to data quality issues. The “Missing reference point elevation” category excludes staids that received WSE-estimated RP (those 358 records were imported).\n\n\n\n\n\n\nExclusions summary\nThe exclusions are now split into two separate tables and export files for hydrologist handoff:\nTable 1 (Not in OVGA list): 75 staids that are not on the current OVGA monitoring points list. These should be reviewed by the hydrologist and DB manager to decide which should be added to the OVGA backend.\nTable 2 (Data quality issues): 49 exclusion entries for staids that are on the OVGA list but excluded for data quality reasons (missing reference point elevation, invalid depth, or invalid RP elevation). The “Missing RP” category in Table 2 excludes staids that received WSE-estimated RP—those were imported via the WSE-estimate-only file (358 records).\nExport files for hydrologist: - ovga_excl_not_in_list_wy2025.csv / .xlsx — Table 1 (not in OVGA list) - ovga_excl_data_quality_wy2025.csv / .xlsx — Table 2 (data quality issues) - ovga_dtw_exclusions_wy2025.csv / .xlsx — Combined file (both tables)\nExclusions by reason and table:\n\n\n\nOVGA DTW exclusions by reason (WY2025). Table 2 Missing RP excludes WSE-estimated staids.\n\n\n\n\n\n\n\nExclusion reason\nUnique staids\nTotal records\nNote\n\n\n\nNot in OVGA monitoring points list\n75\n3745\nTable 1: For hydrologist/DB manager backend list review\n\n\nInvalid depth (NA, -777, or &gt;= 500 ft)\n12\n69\nTable 2: Data quality issue\n\n\nMissing reference point elevation\n37\n392\nTable 2: Staids needing RP (WSE-estimated staids excluded)\n\n\n\n\n\nKey outputs and datasets (output/2025wy/OVGA/):\n\n\n\nOVGA DTW export files and record counts (WY2025).\n\n\n\n\n\n\n\nOutput\nCSV\nXLSX\nRecords / staids\n\n\n\nMain OVGA DTW upload (reported RP only)\novga_uploads_mw_with_rpe_102024_092025_zn.csv\novga_uploads_mw_with_rpe_102024_092025_zn.xlsx\n5,515\n\n\nWSE-estimate-only upload (estimated RP)\novga_uploads_wy2025_wse_estimate_only.csv\novga_uploads_wy2025_wse_estimate_only.xlsx\n358 (imported)\n\n\nTable 1: Not in OVGA list\novga_excl_not_in_list_wy2025.csv\novga_excl_not_in_list_wy2025.xlsx\n75 staids\n\n\nTable 2: Data quality issues\novga_excl_data_quality_wy2025.csv\novga_excl_data_quality_wy2025.xlsx\n49 exclusions\n\n\nCombined exclusions (all reasons)\novga_dtw_exclusions_wy2025.csv\novga_dtw_exclusions_wy2025.xlsx\n124 exclusion rows\n\n\nRP elevation candidates (WSE+DepthRP)\nrp_elev_candidates_wse_plus_dtw_wy2025.csv\nrp_elev_candidates_wse_plus_dtw_wy2025.xlsx\n40 staids\n\n\nRP elevation with sources (reported vs estimated)\nrp_elev_with_sources_wy2025.csv\nrp_elev_with_sources_wy2025.xlsx\n—\n\n\n\n\n\nTable 2 contains 49 unique staids that are on the OVGA list but excluded for data quality reasons (missing RP, invalid depth, or invalid RP). Note that the “Missing RP” category in Table 2 excludes staids that received WSE-estimated RP elevation—those were successfully imported via the WSE-estimate-only file (358 records).\nSummary: WSE + DepthRP estimated staids (already imported)\nThe staids excluded for missing reference point elevation in the original analysis that had sufficient WSE and DepthRP overlap were given estimated RP elevations (see Potential RP elevations derived from WSE + DepthRP in Appendix (with QA/QC)). These staids were imported via the WSE-estimate-only upload file (358 records accepted by OVGA). They no longer appear in Table 2’s “Missing RP” category because they were successfully resolved.\n0 of 37 staids excluded for missing reference point elevation can get an estimated RP from WSE + DepthRP: ****.\nSummary: exclusions “not on OVGA list” that are now on the updated monitoring points list\nIf you have refreshed the monitoring points list from the GLA API export, the following staids were excluded because they were not on the old list but are on the new list. After updating Owens_Monitoring_Points.csv and re-running the report, they would no longer be excluded for that reason.\n6 of 75 staids excluded for not being on the OVGA list are on the updated monitoring points export: T977, T978D, T978S, V137, W426, W428. (If the JSON export has not been refreshed, this shows the last known set.)\nStaids not on OVGA list (handoff for backend)\nThe following staids are excluded from the OVGA DTW upload because they are not on the current OVGA monitoring points list. This list is provided to the hydrologist and DB manager to decide on adding these staids to the OVGA monitoring points list on the backend. Once added, they can be included in future uploads.\n\n\nStaids not on OVGA list: FS3D, FS3S, S004, S005, S006, S007, T1000D, T1000S, T1001D, T1001S, T313B, T936, T937, T938, T939, T940, T977, T978D, T978S, T979, T980, T986D, T986I, T986S, T988D, T988I, T988S, T990D, T990I, T990S, T997D, T997S, T998D, T998S, TS801, TS802, V056D, V056S, V061, V076, V082, V087D, V087S, V137, V145D, V145I, V145S, V208I, V208S, V224D, V224S, V233D, V233S, V243I, V243S, V298I, V298S, V341, V365, V390D, V390I, V932, V933, V934, V935, VCPPDM, VPANCH, VPKIV, VPLACE, VPLANE, VS093, VS360, VWATSON, W426, W428 (75 staids; see exclusions table above for record counts and date ranges; CSV/XLSX download available).\n\nWY2025 OVGA DTW conclusion\nThe WY2025 depth-to-water import to OVGA completed successfully (358 records imported). Exclusions are documented above: staids on the OVGA list but excluded for data-quality reasons (missing RP, invalid depth/RP), and staids not on the OVGA list. The not-on-list staids are highlighted above for handoff to the hydrologist and DB manager to decide on adding them to the OVGA monitoring points list on the backend."
  },
  {
    "objectID": "index.html#record-attrition-by-step",
    "href": "index.html#record-attrition-by-step",
    "title": "Flow Data",
    "section": "Record attrition by step",
    "text": "Record attrition by step\nThe table below summarizes how many records remain after each processing step. Raw reads are joined to reference point elevation, averaged to daily, then filtered to OVGA list and valid depth and RP so the final upload is a subset of the original.\n\n\n\nWY2025 DTW record attrition by processing step.\n\n\n\n\n\n\n\nStep\nRecords\nstringsAsFactors\nPercent_of_raw\n\n\n\nRaw reads (all timestamps)\n89,289\nFALSE\n100%\n\n\nDTW with RP joined (pre-daily)\n89,289\nFALSE\n100%\n\n\nDaily DTW (post-aggregation)\n10,079\nFALSE\n11.3%\n\n\nDaily DTW in OVGA list\n6,334\nFALSE\n7.1%\n\n\nDaily DTW with RP elevation\n5,643\nFALSE\n6.3%\n\n\nFinal OVGA upload\n5,515\nFALSE\n6.2%"
  },
  {
    "objectID": "index.html#gla-data-depth-to-water-import-procedures",
    "href": "index.html#gla-data-depth-to-water-import-procedures",
    "title": "Flow Data",
    "section": "GLA Data Depth to Water Import Procedures",
    "text": "GLA Data Depth to Water Import Procedures\nLast verified in prior annual update; re-check against current OVGA guidance when preparing a new upload.\nGLA Data Web application. The uploaded Excel Workbook must contain one spreadsheet with 13 columns with the following names in this order:\n\n\nField Name\nData Type\nRequired\n\n\nWellName\nText\nYes\n\n\nDateMeasured\nDate\nYes\n\n\nReportingDate\nDate\nNo\n\n\nDepthToWater\nNumeric\nConditional\n\n\nReferencePointElevation\nNumeric\nConditional\n\n\nQAQCLevel\nText\nYes\n\n\nMeasMethod\nText\nYes\n\n\nNoMeasFlag\nText\nConditional\n\n\nQuestMeasFlag\nText\nNo\n\n\nDataSource\nText\nYes\n\n\nCollectedBy\nText\nNo\n\n\nUseInReporting\nText\nNo\n\n\nNotes\nText\nConditional\n\n\nWellName The WellName column is required and must contain the name of a monitoring point within the basin selected when the file was uploaded.\nDateMeasured The DateMeasured column is required. The field must be a date and can not be in the future nor more than 100 years in the past.\n2-1-1 import error says that ReportingDate is not part of the column list ReportingDate The ReportingDate column must be blank or a date. If the field is a date, it must be within 14 days of DateMeasured. If left blank, the column is populated with the value in the DateMeasured column. This field allows users to assign a measurement to an adjacent month for reporting purposes. For example, a measurement collected on May 31st may be intended to be used as an April measurement.\nDepthToWater This column must be blank or numeric. DepthToWater is the number of feet from the reference point. If blank, NoMeasFlag is required and ReferencePointElevation must also be blank. Positive values indicate the water level is below the top of the casing, while negative values indicate the water level is above the top of the casing (flowing artesian conditions).\nReferencePointElevation This column must be blank or numeric. ReferencePointElevation is the elevation in feet from where the depth to water measurement took place. If blank, NoMeasFlag is required and DepthToWater must also be blank.\nQAQCLevel This field is required and must be one of the following values:\n\nHigh - Data are of high quality\nMedium - Data are inconsistent with previous values or sampling conditions were not ideal. Values will be displayed with a different color on plots.\nLow - Data are not considered suitable for display or analysis due to inconsistencies with previous values or poor sampling conditions. Preserves sample in database for record-keeping purposes but not displayed on figures, tables, or used in analyses.\nUndecided - QA/QC level has not been determined.\n\nMeasMethod This field is required and must be one of the following values:\n\n\nCode\nDescription\n\n\nES\nElectric sounder measurement\n\n\nST\nSteel tape measurement\n\n\nAS\nAcoustic or sonic sounder\n\n\nPG\nAirline measurement, pressure gage, or manometer\n\n\nTR\nElectronic pressure transducer\n\n\nOTH\nOther\n\n\nUNK\nUnknown\n\n\nNoMeasFlag This field must be blank if DepthToWater and ReferencePointElevation contain values. Otherwise, this field is required and must be one of the following values:\n\n\nCode\nDescription\n\n\n0\nMeasurement discontinued\n\n\n1\nPumping\n\n\n2\nPump house locked\n\n\n3\nTape hung up\n\n\n4\nCan’t get tape in casing\n\n\n5\nUnable to locate well\n\n\n6\nWell has been destroyed\n\n\n7\nSpecial/other\n\n\n8\nCasing leaking or wet\n\n\n9\nTemporary inaccessible\n\n\nD\nDry well\n\n\nF\nFlowing artesian\n\n\nQuestMeasFlag This field must be blank or be one of the following values:\n\n\nCode\nDescription\n\n\n0\nCaved or deepened\n\n\n1\nPumping\n\n\n2\nNearby pump operating\n\n\n3\nCasing leaking or wet\n\n\n4\nPumped recently\n\n\n5\nAir or pressure gauge measurement\n\n\n6\nOther\n\n\n7\nRecharge or surface water effects near well\n\n\n8\nOil or foreign substance in casing\n\n\n9\nAcoustical sounder\n\n\nE\nRecently flowing\n\n\nF\nFlowing\n\n\nG\nNearby flowing\n\n\nH\nNearby recently flowing\n\n\nDataSource This field is required and used to identify where the water level data came from (e.g., entity, database, file, etc.). Limit is 100 characters. default = “LADWP”\nCollectedBy This field is optional and used to identify the person that physically collected the data. Limit is 50 characters. default = “LADWP”\nUseInReporting This field is optional and used to filter measurements used in reports. If included, the value must be “yes”, “no”, “true”, “false”, “1” or “0”. If blank, a value of “yes” is assumed. default = “yes”\nNotes This field must be populated if NoMeasFlag is 7 (special/other) or QuestMeasFlag is 6 (other), otherwise this field is optional. Limit is 255 characters. default = “blank”"
  },
  {
    "objectID": "index.html#ovga-dtw-record-density-north-to-south",
    "href": "index.html#ovga-dtw-record-density-north-to-south",
    "title": "Flow Data",
    "section": "OVGA DTW record density (north to south)",
    "text": "OVGA DTW record density (north to south)\nThese maps show where records are concentrated north to south for the OVGA DTW upload and for excluded records. Point size scales with record counts. If the ggExtra package is available, a marginal density curve is added to highlight the north-south distribution.\n\n\n\n\nOVGA DTW upload records with north-south density (size scales with record count).\n\n\n\n\n\n\n\nOVGA DTW excluded records with north-south density (size scales with record count)."
  },
  {
    "objectID": "index.html#qaqc",
    "href": "index.html#qaqc",
    "title": "Flow Data",
    "section": "QA/QC and hydrographs",
    "text": "QA/QC and hydrographs\nIn this section we do two things: look at hydrographs (time-series plots of depth to water by well) and run automated checks. Hydrographs let you spot sudden shifts or odd patterns; the checks confirm record counts, missing reference point elevation, and that we only export station IDs that are on the OVGA list. Vertical lines on the plots mark water-year boundaries.\nLaws wellfield\n\n\n\n\nHydrographs of indicator wells in the Laws wellfield.\n\n\n\nBishop wellfield\n\n\n\n\nHydrographs of indicator wells in the Bishop wellfield.\n\n\n\nBig Pine wellfield\n\n\n\n\nHydrographs of indicator wells in the Big Pine wellfield. T565, and V017GC are in south Big Pine near W218/219.\n\n\n\nTaboose-Aberdeen wellfield\n\n\n\n\nHydrographs of indicator wells in the Taboose-Aberdeen wellfield.\n\n\n\nThibaut-Sawmill wellfield\n\n\n\n\nHydrographs of indicator wells in Thibaut-Sawmill wellfield.\n\n\n\nIndependence-Oak wellfield\n\n\n\n\nHydrographs of indicator wells in Independence-Oak wellfield.\n\n\n\nSymmes-Shepherd wellfield\n\n\n\n\nHydrographs of indicator wells in Symmes-Shepherd wellfield.\n\n\n\nBairs-George wellfield\n\n\n\n\nHydrographs of indicator wells in Bairs-George wellfield.\n\n\n\n\n\n\n\n```{r setup, include=FALSE} library(tidyverse) library(lubridate) library(here) library(janitor) library(DT) library(dygraphs) library(zoo) library(writexl) # library(readxl)\nknitr::opts_chunk$set(echo = TRUE,warning = FALSE,message = FALSE,cache=FALSE)\nwy_year &lt;- 2025 wy_short &lt;- sprintf(“%02d”, wy_year %% 100) wy_range &lt;- sprintf(“%02d-%02d”, (wy_year - 1) %% 100, wy_year %% 100)\n\n```{r source-functions, cache=FALSE}\n\nsource(here('code','R','functions.R'))"
  },
  {
    "objectID": "index.html#laws",
    "href": "index.html#laws",
    "title": "Depth to water - annual water year updates",
    "section": "Laws",
    "text": "Laws\n\n\n\n\nHydrographs of indicator wells in the Laws wellfield."
  },
  {
    "objectID": "index.html#bishop",
    "href": "index.html#bishop",
    "title": "Depth to water - annual water year updates",
    "section": "Bishop",
    "text": "Bishop\n\n\n\n\nHydrographs of indicator wells in the Bishop wellfield."
  },
  {
    "objectID": "index.html#big-pine",
    "href": "index.html#big-pine",
    "title": "Depth to water - annual water year updates",
    "section": "Big Pine",
    "text": "Big Pine\n\n\n\n\nHydrographs of indicator wells in the Big Pine wellfield. T565, and V017GC are in south Big Pine near W218/219."
  },
  {
    "objectID": "index.html#taboose-aberdeen",
    "href": "index.html#taboose-aberdeen",
    "title": "Depth to water - annual water year updates",
    "section": "Taboose Aberdeen",
    "text": "Taboose Aberdeen\n\n\n\n\nHydrographs of indicator wells in the Taboose-Aberdeen wellfield."
  },
  {
    "objectID": "index.html#thibaut-sawmill",
    "href": "index.html#thibaut-sawmill",
    "title": "Depth to water - annual water year updates",
    "section": "Thibaut Sawmill",
    "text": "Thibaut Sawmill\n\n\n\n\nHydrographs of indicator wells in Thibaut-Sawmill wellfield."
  },
  {
    "objectID": "index.html#independence-oak",
    "href": "index.html#independence-oak",
    "title": "Depth to water - annual water year updates",
    "section": "Independence Oak",
    "text": "Independence Oak\n\n\n\n\nHydrographs of indicator wells in Independence-Oak wellfield."
  },
  {
    "objectID": "index.html#symmes-shepherd",
    "href": "index.html#symmes-shepherd",
    "title": "Depth to water - annual water year updates",
    "section": "Symmes Shepherd",
    "text": "Symmes Shepherd\n\n\n\n\nHydrographs of indicator wells in Symmes-Shepherd wellfield."
  },
  {
    "objectID": "index.html#bairs-george",
    "href": "index.html#bairs-george",
    "title": "Depth to water - annual water year updates",
    "section": "Bairs George",
    "text": "Bairs George\n\n\n\n\nHydrographs of indicator wells in Bairs George wellfield.\n\n\n\nThe tables below summarize follow-up QA/QC checks after the hydrograph review. They document which staids are excluded, why they are excluded, and whether missing RP elevations can be resolved using ground-surface elevation data. The 77 stations are the ones in the “Missing RP elevations” table (no reported reference point elevation on file). Of these, 0 were included in the WSE-estimate-only upload (358 records imported); the rest remain excluded. The tables below break that group into subsets: not on the OVGA list, or missing ground-surface elevation (GSE) vs having it. The full list of excluded stations and reasons is in the OVGA DTW exclusions table above; use the CSV button there to download it.\nQA/QC enhancement ideas\n\nTrack attrition at each filter step (reference point missing, not in OVGA list, invalid depth).\nFlag staids with large year-over-year shifts in median DTW or seasonal range.\nReport gaps longer than a set threshold (e.g. &gt;90 days) by staid.\nSummarize within-day spread for sites with multiple measurements per day.\nAdd a change-point check to flag step shifts consistent with sensor changes.\nPersist a yearly QA/QC summary CSV to support trend review across years.\n\nMonitoring points present in the update but not on the OVGA list\nThis is the primary exclusion list for the OVGA upload. These staids remain in the internal update but are omitted from the OVGA import because they are not recognized monitoring points in the OVGA basin list.\n\n\n\n\n\n\nPoints missing RP elevations where GSE is missing\nThese staids lack both RP elevations and ground-surface elevation (GSE) metadata, so they cannot be resolved without new reference data.\n\n\n\n\n\n\nPoints missing RP elevations where GSE exists\nThese staids are missing RP elevations but have GSE metadata, which makes them candidates for follow-up resolution.\n\n\n\n\n\n\nMissing-RP points that are not on the OVGA list\nThis subset isolates missing-RP staids that are also not on the OVGA list, which helps separate metadata gaps from OVGA eligibility issues.\n\n\n# A tibble: 0 × 2\n# ℹ 2 variables: staid &lt;chr&gt;, count.na &lt;int&gt;\n\n\nMissing reference point elevation: on the OVGA list\nThese are the highest-priority follow-up items: they are eligible for OVGA import once reference point elevations are provided.\n\n\n\n\n\n\nPotential RP elevations derived from WSE + DepthRP\nIf a staid has both water surface elevation (WSE) and depth-to-water from RP on the same day, an estimated RP elevation can be computed as: RP elevation ≈ WSE + DepthRP. The table below summarizes which missing-RP staids have sufficient overlap to estimate RP elevations.\nThree exports are written to output/2025wy/OVGA/:\n\n\novga_uploads_mw_with_rp_from_wse_wy2025.csv — Full upload: all records with either reported or WSE-estimated RP (same staids as main upload, but with missing RP filled from WSE+DepthRP where possible).\n\novga_uploads_wy2025_wse_estimate_only.csv — OVGA-format subset with only rows that use the WSE+DepthRP estimate for RP elevation. Use this file to try importing just those records in OVGA and confirm they are accepted. A preview table is shown below.\n\nrp_elev_with_sources_wy2025.csv — Updated RP elevation source: one row per staid with staid, rp_elev, and source. Reported values have source = \"reported\"; WSE-estimated values have source = \"wse+rpdtw=rpelev\". Use this to update or tag the canonical rp_elev file.\n\nIf you have saved the monitoring points export as data/hydro/owens_mp_export.json, the report uses it for the “now on new list” summary and the same shape as the CSV list (no need to overwrite the CSV until you are ready). To refresh the CSV from the JSON, run from repo root: Rscript scripts/refresh_owens_monitoring_points.R.\n\n\n\n\n\n\n\n\n\n\nTotal record count missing RP elevations\nThis table summarizes how many records are excluded due to missing reference point elevation, so we can see how much missing metadata affects the OVGA upload.\n\n\n# A tibble: 1 × 1\n  count.na\n     &lt;int&gt;\n1      750\n\n\nSample records from points missing RP elevations\nThese sample records provide a quick QA/QC spot check for missing-RP points and confirm the structure of the daily-aggregated data. (Some of these staids, e.g. T917, have an estimated RP from WSE+DepthRP and were included in the WSE-estimate-only upload that was imported to OVGA; they still appear here because they lack a reported RP on file.)\n\n\n# A tibble: 6 × 4\n# Groups:   staid, date [6]\n  staid date       rp_elev dtw.rp\n  &lt;chr&gt; &lt;date&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n1 F082  2025-05-15      NA   1.85\n2 F082  2025-06-11      NA   1.85\n3 F082  2025-07-14      NA   1.76\n4 F082  2025-08-11      NA   1.81\n5 F082  2025-09-08      NA   1.75\n6 F122  2025-04-09      NA   0.37\n\n\n [1] \"F082\"  \"F122\"  \"T013U\" \"T916\"  \"T917\"  \"T920\"  \"T921\"  \"T924\"  \"T926\" \n[10] \"T930\"  \"W059\"  \"W060\"  \"W063\"  \"W065\"  \"W069\"  \"W074\"  \"W092\"  \"W106\" \n[19] \"W109\"  \"W110\"  \"W111\"  \"W114\"  \"W118\"  \"W140\"  \"W155\"  \"W218\"  \"W219\" \n[28] \"W222\"  \"W223\"  \"W232\"  \"W236\"  \"W239\"  \"W244\"  \"W245\"  \"W247\"  \"W248\" \n[37] \"W330\"  \"W332\"  \"W342\"  \"W343\"  \"W344\"  \"W345\"  \"W346\"  \"W348\"  \"W349\" \n[46] \"W351\"  \"W354\"  \"W355\"  \"W370\"  \"W371\"  \"W374\"  \"W375\"  \"W377\"  \"W382\" \n[55] \"W383\"  \"W384\"  \"W385\"  \"W387\"  \"W388\"  \"W391\"  \"W392\"  \"W393\"  \"W394\" \n[64] \"W395\"  \"W396\"  \"W398\"  \"W401\"  \"W403\"  \"W406\"  \"W407\"  \"W409\"  \"W410\" \n[73] \"W411\"  \"W412\"  \"W413\"  \"W423\"  \"W425\" \n\n\n\n\n\n77 monitoring points lack a reported reference point elevation and are omitted from the main OVGA upload. Of these, 0 staids (e.g. T917) were given an estimated RP from WSE + DepthRP and included in the WSE-estimate-only upload (358 records imported to OVGA). The remainder have no reported RP and no WSE+DepthRP estimate, so they remain excluded."
  },
  {
    "objectID": "planning/wy25checklist.html",
    "href": "planning/wy25checklist.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "planning/wy25checklist.html#prep",
    "href": "planning/wy25checklist.html#prep",
    "title": "",
    "section": "0) Prep",
    "text": "0) Prep\n\nCreate folder data/hydro/2024-25 Water Year Transfer Packet for ICWD/\nAdd new transfer packet files:\n\nDepthRP_2024-25.dat\nDepthGE_2024-25.dat\nOwensValley_DepthWSE_2024-25.dat\nVolumeMonthAF_2024-25.dat\nsummary_stations24-25.csv\n\nVerify/update reference files as needed:\n\ndata/hydro/Owens_Monitoring_Points.csv — latest: log in at owens.gladata.com, open https://owens.gladata.com/api/export.ashx?v=mp, save as data/hydro/owens_mp_export.json, then run Rscript scripts/refresh_owens_monitoring_points.R from repo root (or pass the JSON path)\ndata/hydro/rp_elev.csv\ndata/hydro/gse_staids.csv\ndata/hydro/Production.csv\ndata/hydro/Flows.csv\ndata/hydro/staid_current.csv"
  },
  {
    "objectID": "planning/wy25checklist.html#groundwater-processing-index.qmd",
    "href": "planning/wy25checklist.html#groundwater-processing-index.qmd",
    "title": "",
    "section": "1) Groundwater processing (index.qmd)",
    "text": "1) Groundwater processing (index.qmd)\n\nUpdate input .dat paths to 2024-25 packet\nSet wYear &lt;- '2025'\nPoint RDS read/write to data/hydro/2025/\nUpdate hist source to Monitoring_Wells_Master_2024.csv\nUpdate output names:\n\noutput/testwellwy2025.csv\noutput/Monitoring_Wells_Master_2025.csv\noutput/ovga_uploads_mw_with_rpe_102024_092025_zn.csv\n\nUpdate last_ovga_mw to prior year upload file"
  },
  {
    "objectID": "planning/wy25checklist.html#groundwater-qaqc",
    "href": "planning/wy25checklist.html#groundwater-qaqc",
    "title": "",
    "section": "2) Groundwater QA/QC",
    "text": "2) Groundwater QA/QC\n\nCheck record counts for annual update and master DB\nReview missing RP elevation table\nSpot-check indicator well hydrographs\nConfirm OVGA upload row counts are reasonable vs last year"
  },
  {
    "objectID": "planning/wy25checklist.html#flow-pumping-processing-flow.qmd",
    "href": "planning/wy25checklist.html#flow-pumping-processing-flow.qmd",
    "title": "",
    "section": "3) Flow + Pumping processing (flow.qmd)",
    "text": "3) Flow + Pumping processing (flow.qmd)\n\nUpdate file_path_flow to VolumeMonthAF_2024-25.dat\nUpdate sum_stations to summary_stations24-25.csv\nUpdate monthlies input to totals_means_thru_sep_2024.csv\nUpdate ICWD master outputs:\n\ndata/hydro/totals_means_thru_sep_2025.csv\noutput/totals_means_thru_sep_2025.csv\n\nUpdate OVGA export names:\n\noutput/ovga_swflow_import_wy25.csv\noutput/ovga_production_import_wy24-25.csv (or wy25, pick one)"
  },
  {
    "objectID": "planning/wy25checklist.html#flow-pumping-qaqc",
    "href": "planning/wy25checklist.html#flow-pumping-qaqc",
    "title": "",
    "section": "4) Flow + Pumping QA/QC",
    "text": "4) Flow + Pumping QA/QC\n\nConfirm read != -777 filtering worked\nCheck get_dupes() results for flow + production exports\nSpot-check a few stations and annual totals\nReview QA/QC plots for obvious anomalies"
  },
  {
    "objectID": "planning/wy25checklist.html#render-publish",
    "href": "planning/wy25checklist.html#render-publish",
    "title": "",
    "section": "5) Render + publish",
    "text": "5) Render + publish\n\nRender Quarto site\nVerify docs/index.html and docs/flow.html\nVerify download links point to WY25 outputs\nCommit outputs + docs update"
  },
  {
    "objectID": "planning/wy25checklist.html#github-release-data-capsule-wy2025",
    "href": "planning/wy25checklist.html#github-release-data-capsule-wy2025",
    "title": "",
    "section": "6) GitHub Release data capsule (WY2025)",
    "text": "6) GitHub Release data capsule (WY2025)\n\nCreate a GitHub Release for WY2025 (tag name + title)\nAttach minimal inputs:\n\nDepthRP_2024-25.dat\nDepthGE_2024-25.dat\nOwensValley_DepthWSE_2024-25.dat\nVolumeMonthAF_2024-25.dat\nsummary_stations24-25.csv (when delivered)\nReference files if updated this year (e.g., Owens_Monitoring_Points.csv, rp_elev.csv, gse_staids.csv, Production.csv, Flows.csv, staid_current.csv)\n\nAttach master snapshot used for update:\n\nMonitoring_Wells_Master_2024.csv\n\nAttach WY2025 outputs:\n\noutput/2025wy/ICWD/testwellwy2025.csv\noutput/2025wy/ICWD/Monitoring_Wells_Master_2025.csv\noutput/2025wy/ICWD/totals_means_thru_sep_2025.csv\noutput/2025wy/OVGA/ovga_uploads_mw_with_rpe_102024_092025_zn.csv\noutput/2025wy/OVGA/ovga_swflow_import_wy25.csv\noutput/2025wy/OVGA/ovga_production_import_wy24-25.csv\n\nUpdate package/inst/extdata/manifest.csv to point at release URLs (and refresh checksums)"
  },
  {
    "objectID": "planning/peer_review_pipeline.html",
    "href": "planning/peer_review_pipeline.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "planning/peer_review_pipeline.html#zenodo-doi-release-based",
    "href": "planning/peer_review_pipeline.html#zenodo-doi-release-based",
    "title": "",
    "section": "1) Zenodo DOI (release-based)",
    "text": "1) Zenodo DOI (release-based)\n\nLink the GitHub repo to Zenodo (one-time setup in Zenodo UI).\nAdd release metadata (title, description, version) in GitHub.\nCreate a release tag for each water-year update (e.g., v2025.0).\nVerify Zenodo minted a DOI for the release.\nRecord the DOI in README.md and the report front matter."
  },
  {
    "objectID": "planning/peer_review_pipeline.html#repository-metadata-recommended",
    "href": "planning/peer_review_pipeline.html#repository-metadata-recommended",
    "title": "",
    "section": "2) Repository metadata (recommended)",
    "text": "2) Repository metadata (recommended)\n\nAdd CITATION.cff with project title, authors, and DOI.\n(Optional) Add zenodo.json for detailed metadata.\nConfirm license and versioning strategy (semantic or annual)."
  },
  {
    "objectID": "planning/peer_review_pipeline.html#peerj-submission-path",
    "href": "planning/peer_review_pipeline.html#peerj-submission-path",
    "title": "",
    "section": "3) PeerJ submission path",
    "text": "3) PeerJ submission path\n\nCreate a paper/ directory with:\n\npaper.md (PeerJ-format manuscript in Markdown or Quarto)\nreferences.bib\nfigures/ (exported, final figures)\n\nPreferred submission formats: PDF, Word, LaTeX, or Markdown/HTML. JATS is not required unless requested by the journal.\nExport a PDF from Quarto for submission review.\nAdd a reproducibility section pointing to:\n\nThis repo\nThe Zenodo DOI\nRendered docs/ outputs\n\nKeep results modest and data-driven (trend summaries and QA/QC)."
  },
  {
    "objectID": "planning/peer_review_pipeline.html#optional-jossj0se-track-software-method",
    "href": "planning/peer_review_pipeline.html#optional-jossj0se-track-software-method",
    "title": "",
    "section": "4) Optional JOSS/J0SE track (software method)",
    "text": "4) Optional JOSS/J0SE track (software method)\n\nIf the repo is positioned as a toolchain, add:\n\npaper.md (JOSS format)\npaper.bib\n\nOpen a JOSS/JOSE submission issue when ready."
  },
  {
    "objectID": "planning/peer_review_pipeline.html#annual-cycle-recommended",
    "href": "planning/peer_review_pipeline.html#annual-cycle-recommended",
    "title": "",
    "section": "5) Annual cycle (recommended)",
    "text": "5) Annual cycle (recommended)\n\nOn WY completion:\n\nRender Quarto site\nUpdate outputs in output/\nTag release in GitHub\nConfirm Zenodo DOI minted\nLog summary in planning/worklog.md"
  },
  {
    "objectID": "paper/paper.html",
    "href": "paper/paper.html",
    "title": "Hydro Data: Owens Valley Monitoring Wells, Pumping, and Flow",
    "section": "",
    "text": "ADD_ABSTRACT"
  },
  {
    "objectID": "paper/paper.html#abstract",
    "href": "paper/paper.html#abstract",
    "title": "Hydro Data: Owens Valley Monitoring Wells, Pumping, and Flow",
    "section": "",
    "text": "ADD_ABSTRACT"
  },
  {
    "objectID": "paper/paper.html#introduction",
    "href": "paper/paper.html#introduction",
    "title": "Hydro Data: Owens Valley Monitoring Wells, Pumping, and Flow",
    "section": "Introduction",
    "text": "Introduction\nADD_INTRODUCTION"
  },
  {
    "objectID": "paper/paper.html#data-and-methods",
    "href": "paper/paper.html#data-and-methods",
    "title": "Hydro Data: Owens Valley Monitoring Wells, Pumping, and Flow",
    "section": "Data and Methods",
    "text": "Data and Methods\nADD_METHODS"
  },
  {
    "objectID": "paper/paper.html#results",
    "href": "paper/paper.html#results",
    "title": "Hydro Data: Owens Valley Monitoring Wells, Pumping, and Flow",
    "section": "Results",
    "text": "Results\nADD_RESULTS"
  },
  {
    "objectID": "paper/paper.html#discussion",
    "href": "paper/paper.html#discussion",
    "title": "Hydro Data: Owens Valley Monitoring Wells, Pumping, and Flow",
    "section": "Discussion",
    "text": "Discussion\nADD_DISCUSSION"
  },
  {
    "objectID": "paper/paper.html#reproducibility",
    "href": "paper/paper.html#reproducibility",
    "title": "Hydro Data: Owens Valley Monitoring Wells, Pumping, and Flow",
    "section": "Reproducibility",
    "text": "Reproducibility\nAll code, data, and rendered outputs are available in the project repository. The archived DOI (Zenodo) will be added after release.\nRepository: https://github.com/inyo-gov/hydro-data\nWebsite: https://inyo-gov.github.io/hydro-data/\nDOI: ADD_DOI"
  },
  {
    "objectID": "paper/paper.html#acknowledgments",
    "href": "paper/paper.html#acknowledgments",
    "title": "Hydro Data: Owens Valley Monitoring Wells, Pumping, and Flow",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nADD_ACKNOWLEDGMENTS"
  },
  {
    "objectID": "paper/paper.html#references",
    "href": "paper/paper.html#references",
    "title": "Hydro Data: Owens Valley Monitoring Wells, Pumping, and Flow",
    "section": "References",
    "text": "References\nSee references.bib."
  },
  {
    "objectID": "planning/motherduck_poc.html",
    "href": "planning/motherduck_poc.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "planning/motherduck_poc.html#export-to-parquet-local",
    "href": "planning/motherduck_poc.html#export-to-parquet-local",
    "title": "",
    "section": "1) Export to Parquet (local)",
    "text": "1) Export to Parquet (local)\n\nConvert the primary outputs to Parquet:\n\noutput/Monitoring_Wells_Master_2025.csv\noutput/testwellwy2025.csv\noutput/ovga_uploads_mw_with_rpe_102024_092025_zn.csv\noutput/totals_means_thru_sep_2025.csv\noutput/ovga_swflow_import_wy25.csv\noutput/ovga_production_import_wy24-25.csv\n\n\nExample (duckdb):\nduckdb &lt;&lt;'SQL'\nCOPY (SELECT * FROM read_csv_auto('output/Monitoring_Wells_Master_2025.csv'))\n  TO 'output/Monitoring_Wells_Master_2025.parquet' (FORMAT PARQUET);\nSQL"
  },
  {
    "objectID": "planning/motherduck_poc.html#load-into-motherduck",
    "href": "planning/motherduck_poc.html#load-into-motherduck",
    "title": "",
    "section": "2) Load into MotherDuck",
    "text": "2) Load into MotherDuck\n\nInstall the CLI and authenticate:\n\nduckdb\nINSTALL motherduck; LOAD motherduck;\nATTACH 'md:your_db_name';\n\n\nExample:\nduckdb &lt;&lt;'SQL'\nINSTALL motherduck;\nLOAD motherduck;\nATTACH 'md:hydro_data';\n\nCREATE OR REPLACE TABLE hydro_data.monitoring_wells AS\n  SELECT * FROM read_parquet('output/Monitoring_Wells_Master_2025.parquet');\nSQL"
  },
  {
    "objectID": "planning/motherduck_poc.html#provide-query-examples",
    "href": "planning/motherduck_poc.html#provide-query-examples",
    "title": "",
    "section": "3) Provide query examples",
    "text": "3) Provide query examples\n\nAdd a short “Querying the data” section to README.md (or a docs/ page).\nInclude simple SQL examples (count by staid, yearly totals, etc.)."
  },
  {
    "objectID": "planning/motherduck_poc.html#access-controls",
    "href": "planning/motherduck_poc.html#access-controls",
    "title": "",
    "section": "4) Access controls",
    "text": "4) Access controls\n\nDecide if the MotherDuck database is public or shared by link.\nOptionally provide a read-only token for public query access."
  },
  {
    "objectID": "planning/worklog.html",
    "href": "planning/worklog.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "planning/worklog.html#template",
    "href": "planning/worklog.html#template",
    "title": "",
    "section": "Template",
    "text": "Template\nDate: Task: Tags: Inputs/Files: Notes/Decisions: Outputs: Follow-ups:"
  },
  {
    "objectID": "planning/worklog.html#entries",
    "href": "planning/worklog.html#entries",
    "title": "",
    "section": "Entries",
    "text": "Entries\nDate: 2026-01-28\nTask: Report metadata and site styling updates\nTags: metadata, styling, quarto\nInputs/Files: index.qmd, _quarto.yml, styles.css, www/inyo_logo.png\nNotes/Decisions: Updated author/date-modified and applied Inyo County branding for consistent GitHub Pages styling.\nOutputs: Rendered pages reflect updated theme/logo styling.\nFollow-ups: None.\nDate: 2026-01-28\nTask: WY2025 cache and parsing safeguards\nTags: cache, parsing, wy25\nInputs/Files: index.qmd, flow.qmd, data/hydro/2024-25 Water Year Transfer Packet for ICWD/*.dat\nNotes/Decisions: Moved to year-based cache paths for WY2025 and added fallback parse logic when WY25 RDS files are missing.\nOutputs: WY2025 RDS files generated when missing; year-scoped cache directories in use.\nFollow-ups: None.\nDate: 2026-01-28\nTask: Import-metrics placeholders in reports\nTags: reporting, ovga, tables\nInputs/Files: index.qmd, flow.qmd\nNotes/Decisions: Replaced static screenshots with compact import-metrics tables to keep QA/QC sections current.\nOutputs: Updated report sections ready for metric values.\nFollow-ups: Populate import-metrics tables after final OVGA imports.\nDate: 2026-01-28\nTask: Peer review and Zenodo templates\nTags: peer-review, zenodo, citation\nInputs/Files: CITATION.cff, zenodo.json, paper/*, planning/*\nNotes/Decisions: Templated citation metadata and manuscript scaffolding for PeerJ/Zenodo workflow.\nOutputs: CITATION.cff, zenodo.json, paper/*, planning/peer_review_pipeline.md\nFollow-ups: Fill in placeholders in CITATION.cff and zenodo.json.\nDate: 2026-01-28\nTask: Flow plots and pumping QA/QC buildout\nTags: plots, dygraphs, qaqc, pumping\nInputs/Files: flow.qmd, code/R/functions.R\nNotes/Decisions: Converted key flow plots to dygraphs, added linked-wells QA/QC plots, and introduced wellfield total pumping plots.\nOutputs: Rendered docs/flow.html with interactive flow and pumping QA/QC plots.\nFollow-ups: None.\nDate: 2026-01-29\nTask: OVGA filename parameters and duplicate checks\nTags: ovga, parameters, qaqc\nInputs/Files: flow.qmd\nNotes/Decisions: Standardized OVGA output filenames via wy_year and added “No duplicates found” messaging for quick QA/QC reads.\nOutputs: Updated OVGA export filenames and duplicate-check callouts in report.\nFollow-ups: None.\nDate: 2026-01-29\nTask: Top-10 stream gages and WY/RY labeling\nTags: plots, wy-ry, dygraphs\nInputs/Files: flow.qmd, data/hydro/staid_current.csv\nNotes/Decisions: Replaced single-stream plot with top-10 WY gages and included gage names; clarified WY (Oct–Sep) vs RY (Apr–Mar) in headings and narrative.\nOutputs: Rendered docs/flow.html with top-10 gage plots and clearer year definitions.\nFollow-ups: None.\nDate: 2026-01-29\nTask: Seasonal pumping totals and percentiles\nTags: analysis, tables, pumping, wy-ry\nInputs/Files: flow.qmd, code/R/functions.R\nNotes/Decisions: Added seasonal totals (Apr–Sep, Oct–Mar, Apr–Mar) by site and wellfield plus WY/RY percentile tables for WY2025.\nOutputs: Rendered seasonal totals and percentile tables in docs/flow.html.\nFollow-ups: None.\nDate: 2026-01-29\nTask: Export diffs and raw-data exclusions\nTags: exports, tables, qaqc\nInputs/Files: flow.qmd, data/hydro/Flows.csv, data/hydro/Production.csv\nNotes/Decisions: Added tables comparing last-year vs current exports and raw-data exclusions for flow and production.\nOutputs: Rendered export-diff and exclusions tables in docs/flow.html.\nFollow-ups: None.\nDate: 2026-01-30\nTask: Plot padding for first/last year visibility\nTags: plots, padding, dygraphs\nInputs/Files: flow.qmd, code/R/functions.R\nNotes/Decisions: Added per-series left/right padding so first and last year bars render fully.\nOutputs: Rendered docs/flow.html with no year-end clipping.\nFollow-ups: None.\nDate: 2026-01-30\nTask: Pumping plot scaling and label cleanup\nTags: plots, scaling, labels\nInputs/Files: flow.qmd, code/R/functions.R\nNotes/Decisions: Set y-axis ranges based on stacked totals for Big Pine and exempt-well plots and labeled dygraph values as AF.\nOutputs: Rendered docs/flow.html with corrected y-axis scaling and labels.\nFollow-ups: None.\nDate: 2026-01-30\nTask: RY2025 completeness note\nTags: reporting, wy-ry\nInputs/Files: flow.qmd\nNotes/Decisions: Noted that RY2025 totals are incomplete without Oct–Mar data.\nOutputs: Report note added to docs/flow.html.\nFollow-ups: Revisit once Oct–Mar 2025–26 data are delivered to complete RY2025.\nDate: 2026-01-31\nTask: Package documentation, tests, and checksum validation\nTags: package, tests, checksums, docs\nInputs/Files: package/R/*, package/inst/extdata/manifest.csv, package/tests/*, package/man/*\nNotes/Decisions: Added SHA-256 checksum fields to the manifest and enforced checksum validation in hydrodata_fetch(). Added testthat coverage for manifest fields and checksum format; regenerated .Rd docs.\nOutputs: Package docs and tests updated; manifest now includes checksums.\nFollow-ups: Consider adding checksum verification to the package README examples.\nDate: 2026-01-31\nTask: Vignette expansion and package README note\nTags: package, vignette, examples, documentation\nInputs/Files: package/vignettes/hydro-data-website.Rmd, README.md\nNotes/Decisions: Expanded vignette with example data access for each dataset type and added root README instructions for package install from GitHub.\nOutputs: Vignette now demonstrates DTW, totals, flow, and production access; root README mentions package.\nFollow-ups: None.\nDate: 2026-01-31\nTask: Website build and publication prep\nTags: quarto, website, docs, render\nInputs/Files: index.qmd, flow.qmd, analysis.qmd, docs/\nNotes/Decisions: Ran quarto render to refresh GitHub Pages output. Marked analysis.qmd as draft and removed it from the navbar until ready.\nOutputs: Updated docs/ site build; analysis page excluded.\nFollow-ups: Re-render after title/citation updates to publish the new report title.\nDate: 2026-01-31\nTask: Report title and citation alignment\nTags: metadata, citation, reporting\nInputs/Files: index.qmd, CITATION.cff\nNotes/Decisions: Updated report title to “Depth to water - annual water year updates” for consistency across report and citation.\nOutputs: Title and citation metadata updated in source files.\nFollow-ups: Ensure site build reflects the updated title.\nDate: 2026-01-31\nTask: Flow report citation refresh\nTags: citation, metadata, flow\nInputs/Files: flow.qmd\nNotes/Decisions: Updated flow report citation fields to current date.\nOutputs: Flow report metadata and citation now reflect 2026-01-31.\nFollow-ups: None.\nDate: 2026-01-31\nTask: GitHub Pages rebuilds\nTags: quarto, website, docs, render\nInputs/Files: index.qmd, flow.qmd, docs/\nNotes/Decisions: Re-rendered the site to publish updated titles and citation dates.\nOutputs: Updated docs/index.html and docs/flow.html.\nFollow-ups: None.\nDate: 2026-01-31\nTask: GitHub Releases data capsule checklist\nTags: release, provenance, checklist\nInputs/Files: planning/wy25checklist.md\nNotes/Decisions: Added a release checklist for minimal inputs, master snapshot, and WY2025 outputs for GitHub Releases.\nOutputs: WY25 checklist includes GitHub Releases section.\nFollow-ups: Populate release assets when publishing WY2025.\nDate: 2026-01-31\nTask: Data provenance note in README\nTags: documentation, provenance, release\nInputs/Files: README.md\nNotes/Decisions: Documented GitHub Releases as the data capsule for reproducible annual updates.\nOutputs: README includes data provenance guidance.\nFollow-ups: None.\nDate: 2026-01-31\nTask: Publish commits to GitHub\nTags: git, release, website\nInputs/Files: README.md, planning/wy25checklist.md, docs/\nNotes/Decisions: Merged remote changes, resolved README conflict, and pushed new commits.\nOutputs: Remote main updated with package, site, and documentation changes.\nFollow-ups: None.\nDate: 2026-02-01\nTask: OVGA exclusions with reasons and download CSVs\nTags: ovga, exclusions, qaqc, exports\nInputs/Files: index.qmd, flow.qmd, output/2025wy/OVGA/\nNotes/Decisions: Added staids-excluded-from-OVGA lists with reason (not in OVGA list, missing RP, invalid depth). DTW exclusions CSV includes staid, records, dates, coords, reason; flow and production exclusions CSVs in flow.qmd; combined ovga_exclusions_wy2025.csv when DTW file exists.\nOutputs: ovga_dtw_exclusions_wy2025.csv, ovga_flow_exclusions_wy2025.csv, ovga_production_exclusions_wy2025.csv, optional combined exclusions CSV.\nFollow-ups: None.\nDate: 2026-02-01\nTask: Index narrative, processing steps, and QA/QC descriptions\nTags: reporting, narrative, qaqc, index\nInputs/Files: index.qmd\nNotes/Decisions: Fleshed out plain-language descriptions for data sources, preprocessing, daily harmonization, raw input coverage, RP integration, OVGA export, and QA/QC. Added QA/QC enhancement ideas; removed dated comments; explained daily DTW averaging and each RP/OVGA filter step with brief narrative before tables.\nOutputs: Rendered docs/index.html with clearer section intros and step explanations.\nFollow-ups: None.\nDate: 2026-02-01\nTask: OVGA DTW density maps and record attrition\nTags: maps, qaqc, attrition, plots\nInputs/Files: index.qmd\nNotes/Decisions: Added two density maps (upload vs exclusions) with north–south marginal density; then record-attrition table (counts and % of raw at each step) and attrition maps (all daily → OVGA list → RP filter → final upload); exclusion-type maps (not in OVGA, missing RP, invalid). Section placed after exclusions table so objects exist; empty-map guard for ggMarginal.\nOutputs: Attrition table and multiple maps in docs/index.html.\nFollow-ups: None.\nDate: 2026-02-01\nTask: Raw annual update output and ZRXP caption\nTags: outputs, data, index\nInputs/Files: index.qmd, output/2025wy/ICWD/\nNotes/Decisions: Write full-resolution annual update testwellwy2025_raw.csv (all reads pre–daily aggregation). Added description next to raw-file link; prefixed daily-summary text with “WY2025 update:”. Removed ZRXP file screenshot; kept ascii-ex with caption.\nOutputs: output/2025wy/ICWD/testwellwy2025_raw.csv; updated links and text in report.\nFollow-ups: None.\nDate: 2026-02-01\nTask: RP elevation from WSE + DepthRP and alternate OVGA upload\nTags: ovga, dtw, rp-elevation, qaqc\nInputs/Files: index.qmd, output/2025wy/OVGA/\nNotes/Decisions: For missing-RP staids, check overlap of DepthRP and DepthWSE; estimate RP = WSE + DepthRP (median per staid). Write candidates to CSV; build alternate OVGA DTW upload using estimated RP where reported RP is missing, named by derivation: ovga_uploads_mw_with_rp_from_wse_wy2025.csv. Added note next to OVGA export list describing this alternate file.\nOutputs: rp_elev_candidates_wse_plus_dtw_wy2025.csv, ovga_uploads_mw_with_rp_from_wse_wy2025.csv; note in report.\nFollow-ups: Test alternate upload in OVGA to confirm acceptance.\nDate: 2026-02-01\nTask: Flow report narrative and organization\nTags: reporting, flow, narrative\nInputs/Files: flow.qmd\nNotes/Decisions: Added explanatory text and section intros mirroring index: abstract expansion, data sources/preprocessing, raw input coverage, OVGA flow/production export intros, export comparison and raw exclusions intros, Results/QA/QC section intro.\nOutputs: Rendered docs/flow.html with clearer structure and narrative.\nFollow-ups: Consider adding a note that flow export “WellName” column holds gage IDs for flow (OVGA template reuses WellName for both wells and gages)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This record of data processing is useful internally to speed up these annual tasks. For the most part, the core of the processing has been automated here."
  },
  {
    "objectID": "flow.html",
    "href": "flow.html",
    "title": "Flow Data",
    "section": "",
    "text": "codesource(here('code','R','functions.R'))"
  },
  {
    "objectID": "flow.html#raw-input-coverage",
    "href": "flow.html#raw-input-coverage",
    "title": "Flow Data",
    "section": "Raw input coverage",
    "text": "Raw input coverage\nThe table below summarizes the raw input coverage for the current and prior water years. Use this to confirm record counts and date ranges before merging with historical totals.\n\nraw input coverageraw_flow_coverage &lt;- tibble(\n  File = c(basename(file_path_flow), basename(file_path_flow_prev)),\n  Records = c(nrow(ann.update2), nrow(ann.update_prev2)),\n  Unique_staids = c(\n    dplyr::n_distinct(ann.update2$staid),\n    dplyr::n_distinct(ann.update_prev2$staid)\n  ),\n  Date_start = c(\n    min(ymd_hms(ann.update2$date), na.rm = TRUE),\n    if (nrow(ann.update_prev2) &gt; 0) min(ymd_hms(ann.update_prev2$date), na.rm = TRUE) else as.POSIXct(NA)\n  ),\n  Date_end = c(\n    max(ymd_hms(ann.update2$date), na.rm = TRUE),\n    if (nrow(ann.update_prev2) &gt; 0) max(ymd_hms(ann.update_prev2$date), na.rm = TRUE) else as.POSIXct(NA)\n  )\n)\n\nknitr::kable(raw_flow_coverage)\n\n\n\n\n\n\n\n\n\n\nFile\nRecords\nUnique_staids\nDate_start\nDate_end\n\n\n\nVolumeMonthAF_2024-25.dat\n8853\n744\n2024-10-01\n2025-09-01\n\n\nVolumeMonthAF_2023-24.dat\n8796\n744\n2023-10-01\n2024-09-01\n\n\n\n\n\n\ndate columnsann.update2$datetime &lt;- ymd_hms(ann.update2$date)\n\n\nann.update3&lt;-ann.update2 %&gt;% \n  mutate(year = year(datetime),\n         month = month(datetime),\n         month_abbr = month(datetime, label = TRUE, abbr = TRUE),\n         day = mday(datetime),\n         date.y.m.d = make_date(year, month,day))\n\nann.update4&lt;-ann.update3 %&gt;% \n  select(-date) %&gt;% \n  rename(date = date.y.m.d) %&gt;% \n  left_join(staidlist, by = 'staid') %&gt;% \n  select(staid,description,read,date,year,month,month_abbr) \n\nann.update5 &lt;- ann.update4 %&gt;% \n  mutate(wy = case_when(month &gt;= 10 ~ year + 1,\n                        month &lt;= 9 ~ year),\n         roy = case_when(month &lt;= 3 ~ year - 1,\n                         month &gt;= 4 ~ year),\n         irrag = case_when(month %in% c(4,5,6,7,8,9) ~ year))\n\n\n\nsummary stationsif (nrow(sum_stations) &gt; 0) {\n  sstations &lt;- sum_stations %&gt;% \n    gather(staid,read,-date) %&gt;% \n    left_join(staidlist, by = 'staid') %&gt;% \n    select(-desc_id) %&gt;% \n    mutate(date = as.Date(date),\n           datetime = as.Date(date),\n           month = month(datetime),\n           year = year(datetime),\n           month_abbr = month(datetime, label = TRUE, abbr = TRUE))\n} else {\n  sstations &lt;- ann.update4 %&gt;% slice(0)\n}\n\n\n\nsplit into ovga and ic updatesupdate.merged.ic &lt;- bind_rows(sstations,ann.update4)\nupdate.merged &lt;- ann.update4"
  },
  {
    "objectID": "flow.html#icwd-flow-export",
    "href": "flow.html#icwd-flow-export",
    "title": "Flow Data",
    "section": "ICWD flow export",
    "text": "ICWD flow export\n\nIC date columnsupdate.merged.ic &lt;- update.merged.ic %&gt;% \n  mutate(wy = case_when(month &gt;= 10 ~ year + 1,\n                        month &lt;= 9 ~ year),\n         roy = case_when(month &lt;= 3 ~ year - 1,\n                         month &gt;= 4 ~ year),\n         irrag = case_when(month %in% c(4,5,6,7,8,9) ~ year))\n\n\n\nupdate IC DBtotals_means &lt;- bind_rows(update.merged.ic, monthlies) %&gt;%\n  mutate(date = as.Date(date))\n\n\n\nwrite updated IC DBtotals_means %&gt;% write_csv(here('data','hydro','totals_means_thru_sep_2025.csv'))\nout_icwd &lt;- here(\"output\", \"2025wy\", \"ICWD\")\ndir.create(out_icwd, recursive = TRUE, showWarnings = FALSE)\ntotals_means %&gt;% write_csv(file.path(out_icwd, \"totals_means_thru_sep_2025.csv\"))"
  },
  {
    "objectID": "flow.html#ovga-flow-export",
    "href": "flow.html#ovga-flow-export",
    "title": "Flow Data",
    "section": "OVGA flow export",
    "text": "OVGA flow export\nFlow exports are derived from the monthly flow records after joining flow metadata and filtering to valid OVGA monitoring points. The output is formatted to the OVGA surface-water import template. The OVGA template reuses the “WellName” column for both wells and gages; in the flow export that column holds gage IDs (e.g. SW0373), not well names.\n\nfilter no value -777tm &lt;- ann.update5 %&gt;% filter(read != -777)\n\n\n\nsplit flow vs productionnormalize_flow_staid &lt;- function(x) {\n  ifelse(str_detect(x, \"^0\"), str_replace(x, \"^0+\", \"\"), x)\n}\n\nflowdf &lt;- tm %&gt;% \n  filter(!str_detect(staid, \"[[:alpha:]]\")) %&gt;%\n  mutate(staid = normalize_flow_staid(staid))\n\nflow_ovga &lt;- flowdf %&gt;%\n  left_join(flow.meta, by = 'staid') %&gt;%\n  filter(!is.na(mon_pt_name), mon_pt_name != \"\")\n\nproddf &lt;- tm %&gt;% filter(str_detect(staid, \"[[:alpha:]]\"))\n\n\n\novga flow columnssw.flow &lt;- flow_ovga  %&gt;% \n  mutate(WellName = mon_pt_name,\n         FlowDate = date,\n         FlowRateAcFtPM = read,\n         FlowRateCFS = \"\",\n         FlowRateGPM = \"\") %&gt;% \n  select(WellName,FlowDate,FlowRateAcFtPM, FlowRateCFS, FlowRateGPM)\n\nsw.flow %&gt;%\n  datatable(\n    options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE),\n    class = \"compact stripe\"\n  )\n\n\n\n\n\n\nfind/remove duplicatesdupes &lt;- sw.flow %&gt;% get_dupes() \n\nswflow2 &lt;- sw.flow %&gt;% anti_join(dupes)\n\n\n\nwrite ovga flowout_ovga &lt;- here(\"output\", \"2025wy\", \"OVGA\")\ndir.create(out_ovga, recursive = TRUE, showWarnings = FALSE)\nswflow2 %&gt;% write_csv(file.path(out_ovga, paste0(\"ovga_swflow_import_wy\", wy_short, \".csv\")))\n\n\n\nOVGA flow import metricsflow_import_metrics &lt;- tibble(\n  Metric = c(\n    \"Flow records in upload\",\n    \"Unique monitoring points\",\n    \"Date range\"\n  ),\n  Value = c(\n    nrow(swflow2),\n    dplyr::n_distinct(swflow2$WellName),\n    paste0(min(swflow2$FlowDate, na.rm = TRUE), \" to \", max(swflow2$FlowDate, na.rm = TRUE))\n  )\n) %&gt;% mutate(Value = format(Value, big.mark = \",\"))\n\nknitr::kable(flow_import_metrics)\n\n\n\nMetric\nValue\n\n\n\nFlow records in upload\n6611\n\n\nUnique monitoring points\n555\n\n\nDate range\n2024-10-01 to 2025-09-01\n\n\n\n\n\nFlow export comparison (last year vs current)\nThis comparison highlights which flow gages were added or removed from the OVGA export between WY2024 and WY2025.\n\ncodeflow_export_last_path &lt;- here(\"output\", \"ovga_swflow_import_wy24.csv\")\nflow_export_last &lt;- if (file.exists(flow_export_last_path)) {\n  read_csv(flow_export_last_path, show_col_types = FALSE) %&gt;% distinct(WellName)\n} else {\n  tibble(WellName = character())\n}\n\nflow_export_current &lt;- swflow2 %&gt;% distinct(WellName)\n\nflow_export_missing &lt;- flow_export_last %&gt;% anti_join(flow_export_current, by = \"WellName\")\nflow_export_new &lt;- flow_export_current %&gt;% anti_join(flow_export_last, by = \"WellName\")\n\nDT::datatable(\n  flow_export_missing,\n  options = list(pageLength = 10, lengthChange = TRUE),\n  caption = \"Flow gages in WY2024 export but missing in WY2025 export\"\n)\n\n\n\n\ncodeDT::datatable(\n  flow_export_new,\n  options = list(pageLength = 10, lengthChange = TRUE),\n  caption = \"Flow gages in WY2025 export but not in WY2024 export\"\n)"
  },
  {
    "objectID": "flow.html#ovga-production-export",
    "href": "flow.html#ovga-production-export",
    "title": "Flow Data",
    "section": "OVGA production export",
    "text": "OVGA production export\nProduction exports are derived from monthly production records after joining production metadata and filtering to valid OVGA monitoring points. Missing method values are defaulted to “Unknown” to satisfy the OVGA template.\n\novga production columnsprod_ovga &lt;- proddf %&gt;%\n  left_join(production.meta, by = c('staid' = 'mon_pt_name')) %&gt;%\n  semi_join(ovga_points, by = c(\"staid\" = \"mon_pt_name\"))\n\ntm.well.flow &lt;- prod_ovga %&gt;% \n  mutate(WellName = staid,\n         StartDate = date,\n         EndDate = ceiling_date(date,'month'),\n         AgUsageAF = '',\n         MIUsageAF = read,\n         TotalUsageAF = read,\n         Method = if_else(is.na(method) | method == \"\", \"Unknown\", method),\n         Notes = '') %&gt;% \n  select(WellName,StartDate,EndDate, AgUsageAF, MIUsageAF, TotalUsageAF, Method, Notes)\n\n\n\ncodetm.well.flow %&gt;%\n  datatable(\n    options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE),\n    class = \"compact stripe\"\n  )\n\n\n\n\n\n\nfind/replace duplicatesdupeswell &lt;- tm.well.flow %&gt;% get_dupes()\nif (nrow(dupeswell) == 0) {\n  cat(\"No duplicates found.\\n\")\n} else {\n  cat(\"Duplicate rows found: \", nrow(dupeswell), \"\\n\")\n  dupeswell\n}\n\nNo duplicates found.\n\n\n\nwrite ovga productionout_ovga &lt;- here(\"output\", \"2025wy\", \"OVGA\")\ndir.create(out_ovga, recursive = TRUE, showWarnings = FALSE)\ntm.well.flow %&gt;% write_csv(file.path(out_ovga, paste0(\"ovga_production_import_wy\", wy_range, \".csv\")))\nwritexl::write_xlsx(tm.well.flow, file.path(out_ovga, paste0(\"ovga_production_import_wy\", wy_range, \".xlsx\")))\n\n\n\nOVGA production import metricsproduction_import_metrics &lt;- tibble(\n  Metric = c(\n    \"Production records in upload\",\n    \"Unique production wells\",\n    \"Date range\"\n  ),\n  Value = c(\n    nrow(tm.well.flow),\n    dplyr::n_distinct(tm.well.flow$WellName),\n    paste0(min(tm.well.flow$StartDate, na.rm = TRUE), \" to \", max(tm.well.flow$EndDate, na.rm = TRUE))\n  )\n) %&gt;% mutate(Value = format(Value, big.mark = \",\"))\n\nknitr::kable(production_import_metrics)\n\n\n\nMetric\nValue\n\n\n\nProduction records in upload\n1956\n\n\nUnique production wells\n162\n\n\nDate range\n2024-10-01 to 2025-10-01\n\n\n\n\n\nProduction export comparison (last year vs current)\nThis comparison highlights which production wells were added or removed from the OVGA export between WY2024 and WY2025.\n\ncodeproduction_export_last_path &lt;- here(\"output\", \"ovga_production_import_wy23-24.csv\")\nproduction_export_last &lt;- if (file.exists(production_export_last_path)) {\n  read_csv(production_export_last_path, show_col_types = FALSE) %&gt;% distinct(WellName)\n} else {\n  tibble(WellName = character())\n}\n\nproduction_export_current &lt;- tm.well.flow %&gt;% distinct(WellName)\n\nproduction_export_missing &lt;- production_export_last %&gt;% anti_join(production_export_current, by = \"WellName\")\nproduction_export_new &lt;- production_export_current %&gt;% anti_join(production_export_last, by = \"WellName\")\n\nDT::datatable(\n  production_export_missing,\n  options = list(pageLength = 10, lengthChange = TRUE),\n  caption = \"Production wells in WY2024 export but missing in WY2025 export\"\n)\n\n\n\n\ncodeDT::datatable(\n  production_export_new,\n  options = list(pageLength = 10, lengthChange = TRUE),\n  caption = \"Production wells in WY2025 export but not in WY2024 export\"\n)\n\n\n\n\n\nRaw data exclusions (last year vs current)\nThese tables show staids present in the raw input data but excluded from the export, which helps isolate metadata gaps or OVGA list mismatches.\n\ncoderaw_flow_current &lt;- ann.update2 %&gt;%\n  filter(!str_detect(staid, \"[[:alpha:]]\")) %&gt;%\n  mutate(staid = normalize_flow_staid(staid))\n\nraw_flow_prev &lt;- ann.update_prev2 %&gt;%\n  filter(!str_detect(staid, \"[[:alpha:]]\")) %&gt;%\n  mutate(staid = normalize_flow_staid(staid))\n\nraw_prod_current &lt;- ann.update2 %&gt;%\n  filter(str_detect(staid, \"[[:alpha:]]\"))\n\nraw_prod_prev &lt;- ann.update_prev2 %&gt;%\n  filter(str_detect(staid, \"[[:alpha:]]\"))\n\nraw_flow_current_joined &lt;- raw_flow_current %&gt;%\n  left_join(flow.meta, by = \"staid\")\n\nraw_flow_prev_joined &lt;- raw_flow_prev %&gt;%\n  left_join(flow.meta, by = \"staid\")\n\nraw_flow_excluded_current &lt;- raw_flow_current_joined %&gt;%\n  filter(is.na(mon_pt_name) | !(mon_pt_name %in% flow_export_current$WellName)) %&gt;%\n  distinct(staid, mon_pt_name) %&gt;%\n  arrange(staid)\n\nraw_flow_excluded_prev &lt;- raw_flow_prev_joined %&gt;%\n  filter(is.na(mon_pt_name) | !(mon_pt_name %in% flow_export_last$WellName)) %&gt;%\n  distinct(staid, mon_pt_name) %&gt;%\n  arrange(staid)\n\nraw_prod_excluded_current &lt;- raw_prod_current %&gt;%\n  distinct(staid) %&gt;%\n  filter(!staid %in% production_export_current$WellName) %&gt;%\n  arrange(staid)\n\nraw_prod_excluded_prev &lt;- raw_prod_prev %&gt;%\n  distinct(staid) %&gt;%\n  filter(!staid %in% production_export_last$WellName) %&gt;%\n  arrange(staid)\n\nDT::datatable(\n  raw_flow_excluded_prev,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE),\n  caption = \"Flow staids in WY2024 raw data excluded from WY2024 export\"\n)\n\n\n\n\ncodeDT::datatable(\n  raw_flow_excluded_current,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE),\n  caption = \"Flow staids in WY2025 raw data excluded from WY2025 export\"\n)\n\n\n\n\ncodeDT::datatable(\n  raw_prod_excluded_prev,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE),\n  caption = \"Production staids in WY2024 raw data excluded from WY2024 export\"\n)\n\n\n\n\ncodeDT::datatable(\n  raw_prod_excluded_current,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE),\n  caption = \"Production staids in WY2025 raw data excluded from WY2025 export\"\n)\n\n\n\n\n\nRemoved staids not on the basin list are excluded from OVGA exports and reflected in the raw‑data exclusion tables above.\nOVGA flow and production exclusions (download)\n\nflow/production staids excluded from OVGA exportsflow_exclusions &lt;- flowdf %&gt;%\n  left_join(flow.meta, by = \"staid\") %&gt;%\n  filter(is.na(mon_pt_name) | mon_pt_name == \"\") %&gt;%\n  group_by(staid) %&gt;%\n  summarise(\n    records = n(),\n    first_date = min(date, na.rm = TRUE),\n    last_date = max(date, na.rm = TRUE),\n    mon_pt_name = dplyr::first(mon_pt_name),\n    .groups = \"drop\"\n  ) %&gt;%\n  left_join(staidlist, by = \"staid\") %&gt;%\n  mutate(\n    dataset = \"flow\",\n    reason = \"Missing flow metadata mapping (Flows.csv)\"\n  ) %&gt;%\n  select(\n    dataset,\n    staid,\n    description,\n    records,\n    first_date,\n    last_date,\n    mon_pt_name,\n    reason\n  ) %&gt;%\n  arrange(staid)\n\nprod_exclusions &lt;- proddf %&gt;%\n  anti_join(ovga_points, by = c(\"staid\" = \"mon_pt_name\")) %&gt;%\n  left_join(production.meta, by = c(\"staid\" = \"mon_pt_name\")) %&gt;%\n  group_by(staid) %&gt;%\n  summarise(\n    records = n(),\n    first_date = min(date, na.rm = TRUE),\n    last_date = max(date, na.rm = TRUE),\n    method = dplyr::first(method),\n    .groups = \"drop\"\n  ) %&gt;%\n  left_join(staidlist, by = \"staid\") %&gt;%\n  mutate(\n    dataset = \"production\",\n    reason = \"Not in OVGA monitoring points list\"\n  ) %&gt;%\n  select(\n    dataset,\n    staid,\n    description,\n    records,\n    first_date,\n    last_date,\n    method,\n    reason\n  ) %&gt;%\n  arrange(staid)\n\nout_ovga &lt;- here(\"output\", \"2025wy\", \"OVGA\")\ndir.create(out_ovga, recursive = TRUE, showWarnings = FALSE)\n\nflow_exclusions %&gt;%\n  write_csv(file.path(out_ovga, paste0(\"ovga_flow_exclusions_wy\", wy_year, \".csv\")))\nwritexl::write_xlsx(flow_exclusions, file.path(out_ovga, paste0(\"ovga_flow_exclusions_wy\", wy_year, \".xlsx\")))\nprod_exclusions %&gt;%\n  write_csv(file.path(out_ovga, paste0(\"ovga_production_exclusions_wy\", wy_year, \".csv\")))\nwritexl::write_xlsx(prod_exclusions, file.path(out_ovga, paste0(\"ovga_production_exclusions_wy\", wy_year, \".xlsx\")))\n\ndtw_exclusions_path &lt;- file.path(out_ovga, \"ovga_dtw_exclusions_wy2025.csv\")\nif (file.exists(dtw_exclusions_path)) {\n  dtw_exclusions &lt;- read_csv(dtw_exclusions_path, show_col_types = FALSE)\n  ovga_exclusions &lt;- bind_rows(dtw_exclusions, flow_exclusions, prod_exclusions)\n  ovga_exclusions %&gt;%\n    write_csv(file.path(out_ovga, paste0(\"ovga_exclusions_wy\", wy_year, \".csv\")))\n  writexl::write_xlsx(ovga_exclusions, file.path(out_ovga, paste0(\"ovga_exclusions_wy\", wy_year, \".xlsx\")))\n}\n\nDT::datatable(\n  flow_exclusions,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE),\n  class = \"compact stripe\",\n  caption = \"Flow staids excluded from OVGA export (WY2025)\"\n)\n\n\n\n\nflow/production staids excluded from OVGA exportsDT::datatable(\n  prod_exclusions,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE),\n  class = \"compact stripe\",\n  caption = \"Production staids excluded from OVGA export (WY2025)\"\n)"
  },
  {
    "objectID": "flow.html#totals-and-means---summary-stations-requested",
    "href": "flow.html#totals-and-means---summary-stations-requested",
    "title": "Flow Data",
    "section": "Totals and Means - summary stations requested",
    "text": "Totals and Means - summary stations requested\nSummary-station series (OVR, OVPW, etc.) are populated from the summary stations file. Until summary_stations24-25.csv is delivered, these plots will extend through WY2024.\nOVR Owens Valley Runoff\n\ncodetm2 &lt;- totals_means\nmonthly_uses_syncplot(staid_p = \"OVR\" ,data = tm2, group_name = 'ov')\n\n\nOwens Valley Runoff\n\n\nOVPW Owens Valley Pumped Water\n\ncodemonthly_uses_syncplot(staid_p = \"OVPW\" ,data = tm2, group_name = 'ov')\n\n\nOwens Valley Pumped Water\n\n\nFTC L.A.A. Total Flow to the City\n\ncodemonthly_uses_syncplot(staid_p = \"FTC\" ,data = tm2, group_name = 'ov')\n\n\nLAA Total Flow to the City\n\n\nLOLU Lower Owens River Project – Lakes and Ponds Use\n\ncodemonthly_uses_syncplot(staid_p = \"LOLU\" ,data = tm2, group_name = 'ov')\n\n\nLower Owens River Project – Lakes and Ponds Use\n\n\nLOOU Lower Owens River Project – Operations\n\ncodemonthly_uses_syncplot(staid_p = \"LOOU\" ,data = tm2, group_name = 'ov')\n\n\nLower Owens River Project – Operations\n\n\nLORPDU Lower Owens River – Delta Uses\n\ncodemonthly_uses_syncplot(staid_p = \"LORPDU\" ,data = tm2, group_name = 'ov')\n\n\nLower Owens River – Delta Uses\n\n\nLORPRU Lower Owens River – River Uses\n\ncodemonthly_uses_syncplot(staid_p = \"LORPRU\" ,data = tm2, group_name = 'ov')\n\n\nLower Owens River – River Uses\n\n\nLORPTU Lower Owens River Project Total Uses\n\ncodemonthly_uses_syncplot(staid_p = \"LORPTU\" ,data = tm2, group_name = 'ov')\n\n\nLower Owens River Project Total Uses\n\n\nLOWU Lower Owens River Project – Waterfowl Uses\n\ncodemonthly_uses_syncplot(staid_p = \"LOWU\" ,data = tm2, group_name = 'ov')\n\n\nLower Owens River Project – Waterfowl Uses\n\n\nMBR Mono Basin Runoff\n\ncodemonthly_uses_syncplot(staid_p = \"MBR\" ,data = tm2, group_name = 'ov')\n\n\nMono Basin Runoff\n\n\nMTWP Mono Tunnel at West Portal\n\ncodemonthly_uses_syncplot(staid_p = \"MTWP\" ,data = tm2, group_name = 'ov')\n\n\nMono Tunnel at West Portal\n\n\nOLTU Owens Lake Total Uses\n\ncodemonthly_uses_syncplot(staid_p = \"OLTU\" ,data = tm2, group_name = 'ov')\n\n\nOwens Lake Total Uses\n\n\nOVFG Owens Valley Flowing Groundwater\n\ncodemonthly_uses_syncplot(staid_p = \"OVFG\" ,data = tm2, group_name = 'ov')\n\n\nOwens Valley Flowing Groundwater\n\n\nOVGR Owens Valley Groundwater Recharge\n\ncodemonthly_uses_syncplot(staid_p = \"OVGR\" ,data = tm2, group_name = 'ov')\n\n\nOwens Valley Groundwater Recharge\n\n\nOVIR Owens Valley Irrigation\n\ncodemonthly_uses_syncplot(staid_p = \"OVIR\" ,data = tm2, group_name = 'ov')\n\n\nOwens Valley Irrigation\n\n\nSHTO South Haiwee Total Outflow (1+2+3+BP)\n\ncodemonthly_uses_syncplot(staid_p = \"SHTO\" ,data = tm2, group_name = 'ov')\n\n\nSouth Haiwee Total Outflow (1+2+3+BP)"
  },
  {
    "objectID": "flow.html#stream-flow",
    "href": "flow.html#stream-flow",
    "title": "Flow Data",
    "section": "Stream flow",
    "text": "Stream flow\nTop 10 stream gages by WY2025 volume (water year Oct-Sep)\n\ncodeflow_wy &lt;- flowdf %&gt;%\n  mutate(wy = if_else(month &gt;= 10, year + 1, year))\n\ntop_streams &lt;- flow_wy %&gt;%\n  filter(wy == wy_year) %&gt;%\n  group_by(staid) %&gt;%\n  summarise(total_af = sum(read, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  arrange(desc(total_af)) %&gt;%\n  slice_head(n = 10) %&gt;%\n  left_join(flow.meta, by = \"staid\")\n\ntop_streams &lt;- top_streams %&gt;%\n  mutate(display_name = if_else(is.na(mon_pt_name) | mon_pt_name == \"\", staid, mon_pt_name))\n\nplots &lt;- purrr::map2(top_streams$staid, top_streams$display_name, ~{\n  plot_title &lt;- paste0(.y, \" (\", .x, \")\")\n  htmltools::tagList(\n    htmltools::tags$h4(plot_title),\n    monthly_flow_syncplot_staid(staid_p = .x, data = totals_means, group_name = \"a\", title = plot_title)\n  )\n})\n\nhtmltools::tagList(plots)\n\nSW0050 (50)\n\nSW0077 (77)\n\nSW2066 (2066)\n\nSW0049 (49)\n\n413 (413)\n\nSW3289 (3289)\n\nSW0118 (118)\n\nSW0116 (116)\n\nSW3324 (3324)\n\nSW0088 (88)"
  },
  {
    "objectID": "flow.html#pumping",
    "href": "flow.html#pumping",
    "title": "Flow Data",
    "section": "Pumping",
    "text": "Pumping\nRunoff year (Apr-Mar) pumping totals are reported below. Water year (Oct-Sep) is used for the flow series above. RY2025 totals are partial because Oct–Mar 2025–26 data have not yet been delivered.\n\ncodetozoo &lt;- function(x) zoo(x$total_pumping, x$roy2)\ndyMultiColumn &lt;- function(dygraph) {\n  dyPlotter(dygraph = dygraph,\n            name = \"MultiColumn\",\n            path = system.file(\"plotters/multicolumn.js\",\n                               package = \"dygraphs\"))\n}\n\nplot_wellfield_total &lt;- function(data, field_sites, linked_wells_sites, title, value_range = NULL) {\n  linked_wells &lt;- linked_wells_sites %&gt;%\n    filter(Site %in% field_sites) %&gt;%\n    pull(Linked_Well) %&gt;%\n    unique()\n\n  if (length(linked_wells) == 0) {\n    return(NULL)\n  }\n\n  df &lt;- data %&gt;%\n    filter(staid %in% linked_wells) %&gt;%\n    mutate(read = if_else(read == -777, 0, read)) %&gt;%\n    group_by(roy, staid) %&gt;%\n    summarise(total_pumping = sum(read, na.rm = TRUE), .groups = \"drop\") %&gt;%\n    mutate(roy2 = make_date(roy, 4, 1))\n\n  df &lt;- pad_series_bounds(df, \"roy2\", \"staid\", months_start = 6, months_end = 18)\n\n  year_totals &lt;- df %&gt;%\n    group_by(roy2) %&gt;%\n    summarise(total_pumping = sum(total_pumping, na.rm = TRUE), .groups = \"drop\")\n  y_max &lt;- max(year_totals$total_pumping, na.rm = TRUE)\n\n  plot_data &lt;- do.call(merge, lapply(split(df, df$staid), tozoo))\n  plot &lt;- plot_data %&gt;%\n    dygraph(main = title, group = \"a\") %&gt;%\n    dyStackedBarGroup(linked_wells) %&gt;%\n    dyBarChart() %&gt;%\n    dyAxis(\"y\", label = \"Total Annual Pumping (AF)\", axisLabelWidth = 70)\n\n  if (is.finite(y_max)) {\n    plot &lt;- plot %&gt;% dyAxis(\"y\", valueRange = c(0, y_max * 1.05))\n  }\n\n  if (!is.null(value_range)) {\n    plot &lt;- plot %&gt;% dyAxis(\"y\", valueRange = value_range)\n  }\n\n  plot\n}\n\ncompute_linked_seasonal &lt;- function(data, linked_wells_sites, group_map, group_col, target_year = 2025) {\n  base &lt;- data %&gt;%\n    filter(staid %in% linked_wells_sites$Linked_Well) %&gt;%\n    mutate(\n      read = if_else(read &lt; 0, 0, read),\n      date = as.Date(date),\n      year = year(date),\n      month = month(date),\n      wy = if_else(month &gt;= 10, year + 1, year),\n      runoff_year = if_else(month &gt;= 4, year, year - 1),\n      season = case_when(\n        month %in% 4:9 ~ \"Apr-Sep\",\n        month %in% c(10, 11, 12, 1, 2, 3) ~ \"Oct-Mar\",\n        TRUE ~ NA_character_\n      )\n    ) %&gt;%\n    left_join(group_map, by = c(\"staid\" = \"Linked_Well\")) %&gt;%\n    filter(!is.na(.data[[group_col]]))\n\n  seasonal_wy &lt;- base %&gt;%\n    group_by(.data[[group_col]], wy, season) %&gt;%\n    summarise(total_pumping = sum(read, na.rm = TRUE), .groups = \"drop\") %&gt;%\n    pivot_wider(names_from = season, values_from = total_pumping) %&gt;%\n    rename(Group = !!sym(group_col), WY = wy) %&gt;%\n    arrange(Group, WY)\n\n  runoff_ry &lt;- base %&gt;%\n    group_by(.data[[group_col]], runoff_year) %&gt;%\n    summarise(`Apr-Mar` = sum(read, na.rm = TRUE), .groups = \"drop\") %&gt;%\n    rename(Group = !!sym(group_col), RY = runoff_year) %&gt;%\n    arrange(Group, RY)\n\n  percentiles_wy &lt;- seasonal_wy %&gt;%\n    group_by(Group) %&gt;%\n    mutate(\n      `Apr-Sep pct` = if_else(\n        is.na(`Apr-Sep`),\n        NA_real_,\n        round(dplyr::percent_rank(`Apr-Sep`) * 100, 1)\n      ),\n      `Oct-Mar pct` = if_else(\n        is.na(`Oct-Mar`),\n        NA_real_,\n        round(dplyr::percent_rank(`Oct-Mar`) * 100, 1)\n      )\n    ) %&gt;%\n    ungroup() %&gt;%\n    filter(WY == target_year) %&gt;%\n    select(Group, WY, `Apr-Sep`, `Apr-Sep pct`, `Oct-Mar`, `Oct-Mar pct`)\n\n  percentiles_ry &lt;- runoff_ry %&gt;%\n    group_by(Group) %&gt;%\n    mutate(\n      `Apr-Mar pct` = if_else(\n        is.na(`Apr-Mar`),\n        NA_real_,\n        round(dplyr::percent_rank(`Apr-Mar`) * 100, 1)\n      )\n    ) %&gt;%\n    ungroup() %&gt;%\n    filter(RY == target_year) %&gt;%\n    select(Group, RY, `Apr-Mar`, `Apr-Mar pct`)\n\n  list(\n    seasonal_wy = seasonal_wy,\n    runoff_ry = runoff_ry,\n    percentiles_wy = percentiles_wy,\n    percentiles_ry = percentiles_ry\n  )\n}"
  },
  {
    "objectID": "flow.html#linked-wells-qaqc",
    "href": "flow.html#linked-wells-qaqc",
    "title": "Flow Data",
    "section": "Linked Wells QA/QC",
    "text": "Linked Wells QA/QC\nLinked-well pumping plots from the on/off management program support visual QA/QC of annual totals.\n\ncodetm2 &lt;- totals_means\n\nlinked_wells_sites &lt;- data.frame(\n  Site = rep(\n    c(\n      \"BP1\", \"BP2\", \"BP3\", \"BP4\",\n      \"LW1\", \"LW2\", \"LW3\",\n      \"TA3\", \"TA4\", \"TA5\", \"TA6\",\n      \"TS1\", \"TS2\", \"TS3\", \"TS4\",\n      \"IO1\", \"IO2\",\n      \"SS1\", \"SS2\", \"SS3\", \"SS4\",\n      \"BG2\"\n    ),\n    times = c(4, 4, 4, 1, 4, 4, 5, 4, 2, 1, 2, 1, 1, 3, 2, 3, 1, 3, 3, 2, 2, 4)\n  ),\n  Linked_Well = c(\n    \"W210\", \"W378\", \"W379\", \"W389\",   # BP1\n    \"W220\", \"W229\", \"W374\", \"W375\",   # BP2\n    \"W222\", \"W223\", \"W231\", \"W232\",   # BP3\n    \"W331\",                            # BP4\n    \"W247\", \"W248\", \"W249\", \"W398\",   # LW1\n    \"W236\", \"W239\", \"W243\", \"W244\",   # LW2\n    \"W240\", \"W241\", \"W399\", \"W376\", \"W377\", # LW3\n    \"W106\", \"W110\", \"W111\", \"W114\",   # TA3\n    \"W342\", \"W347\",                   # TA4\n    \"W349\",                           # TA5\n    \"W109\", \"W370\",                   # TA6\n    \"W159\",                           # TS1\n    \"W155\",                           # TS2\n    \"W103\", \"W104\", \"W382\",           # TS3\n    \"W380\", \"W381\",                   # TS4\n    \"W061\", \"W391\", \"W400\",           # IO1\n    \"W063\",                           # IO2\n    \"W069\", \"W392\", \"W393\",           # SS1\n    \"W074\", \"W394\", \"W395\",           # SS2\n    \"W092\", \"W396\",                   # SS3\n    \"W075\", \"W345\",                   # SS4\n    \"W076\", \"W403\", \"W343\", \"W348\"    # BG2\n  )\n)\n\nwellfield_sites &lt;- tibble(\n  Wellfield = c(\n    \"Laws\",\n    \"Big Pine\",\n    \"Taboose/Aberdeen\",\n    \"Thibaut/Sawmill\",\n    \"Independence/Oak\",\n    \"Symmes/Shepherd\",\n    \"Bairs/Georges\"\n  ),\n  Site = I(list(\n    c(\"LW1\", \"LW2\", \"LW3\"),\n    c(\"BP1\", \"BP2\", \"BP3\", \"BP4\"),\n    c(\"TA3\", \"TA4\", \"TA5\", \"TA6\"),\n    c(\"TS1\", \"TS2\", \"TS3\", \"TS4\"),\n    c(\"IO1\", \"IO2\"),\n    c(\"SS1\", \"SS2\", \"SS3\", \"SS4\"),\n    c(\"BG2\")\n  ))\n) %&gt;%\n  unnest(Site)\n\nsite_map &lt;- linked_wells_sites %&gt;% select(Linked_Well, Site)\nwellfield_map &lt;- linked_wells_sites %&gt;%\n  left_join(wellfield_sites, by = \"Site\") %&gt;%\n  select(Linked_Well, Wellfield)\n\nseasonal_by_site &lt;- compute_linked_seasonal(tm2, linked_wells_sites, site_map, \"Site\", target_year = wy_year)\nseasonal_by_wellfield &lt;- compute_linked_seasonal(tm2, linked_wells_sites, wellfield_map, \"Wellfield\", target_year = wy_year)\n\n\nSeasonal totals use water year (WY, Oct–Sep end year) for Apr–Sep and Oct–Mar. Runoff totals use runoff year (RY, Apr–Mar start year). Example: RY2025 = Apr 2025–Mar 2026.\nSeasonal pumping totals by site (water year Oct-Sep)\n\ncodeDT::datatable(\n  seasonal_by_site$seasonal_wy,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE)\n)\n\n\n\n\n\nRunoff year totals by site (Apr-Mar)\n\ncodeDT::datatable(\n  seasonal_by_site$runoff_ry,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE)\n)\n\n\n\n\n\nWY2025 percentiles by site (water year Oct-Sep)\nPercentiles are calculated within each site using the historical distribution of Apr–Sep totals (and separately Oct–Mar totals). WY2025 percentiles therefore rank the 2025 six‑month total against all prior years for that site.\n\ncodeDT::datatable(\n  seasonal_by_site$percentiles_wy,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE)\n)\n\n\n\n\n\nRY2025 percentiles by site (runoff year Apr-Mar)\n\ncodeDT::datatable(\n  seasonal_by_site$percentiles_ry,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE)\n)\n\n\n\n\n\nSeasonal pumping totals by wellfield (water year Oct-Sep)\n\ncodeDT::datatable(\n  seasonal_by_wellfield$seasonal_wy,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE)\n)\n\n\n\n\n\nRunoff year totals by wellfield (Apr-Mar)\n\ncodeDT::datatable(\n  seasonal_by_wellfield$runoff_ry,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE)\n)\n\n\n\n\n\nWY2025 percentiles by wellfield (water year Oct-Sep)\nPercentiles are calculated within each wellfield using the historical distribution of Apr–Sep totals (and separately Oct–Mar totals). WY2025 percentiles therefore rank the 2025 six‑month total against all prior years for that wellfield.\n\ncodeDT::datatable(\n  seasonal_by_wellfield$percentiles_wy,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE)\n)\n\n\n\n\n\nRY2025 percentiles by wellfield (runoff year Apr-Mar)\n\ncodeDT::datatable(\n  seasonal_by_wellfield$percentiles_ry,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE)\n)\n\n\n\n\n\nLaws Monitoring Site #1 (LW1)\n\ncodeplot_linked_wells(tm2, \"LW1\", linked_wells_sites)\n\n\n\n\n\nLaws Monitoring Site #2 (LW2)\n\ncodeplot_linked_wells(tm2, \"LW2\", linked_wells_sites)\n\n\n\n\n\nLaws Monitoring Site #3 (LW3)\n\ncodeplot_linked_wells(tm2, \"LW3\", linked_wells_sites)\n\n\n\n\n\nLaws Wellfield Total Pumping\n\ncodeplot_wellfield_total(\n  tm2,\n  field_sites = c(\"LW1\", \"LW2\", \"LW3\"),\n  linked_wells_sites = linked_wells_sites,\n  title = \"Laws Wellfield Total Pumping\"\n)\n\n\n\n\n\nBig Pine Monitoring Site #1 (BP1)\n\ncodeplot_linked_wells(tm2, \"BP1\", linked_wells_sites)\n\n\n\n\n\nBig Pine Monitoring Site #2 (BP2)\n\ncodeplot_linked_wells(tm2, \"BP2\", linked_wells_sites)\n\n\n\n\n\nBig Pine Monitoring Site #3 (BP3)\n\ncodeplot_linked_wells(tm2, \"BP3\", linked_wells_sites)\n\n\n\n\n\nBig Pine Monitoring Site #4 (BP4)\n\ncodeplot_linked_wells_single(tm2, \"BP4\", linked_wells_sites)\n\n\n\n\n\nExempt Wells - Fish Hatchery and 218, 219\n\ncodelinked_wells &lt;- c(\"W218\",\"W219\",\"W330\",\"W332\")\n\nDF &lt;- tm2 %&gt;%\n  filter(staid %in% linked_wells) %&gt;%\n  mutate(read = if_else(read == -777, 0, read)) %&gt;%\n  group_by(roy, staid) %&gt;%\n  summarise(total_pumping = sum(read, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  mutate(roy2 = make_date(roy, 4, 1))\n\nDF &lt;- pad_series_bounds(DF, \"roy2\", \"staid\", months_start = 6, months_end = 18)\n\nData &lt;- do.call(merge, lapply(split(DF, DF$staid), tozoo))\nyear_totals_exempt &lt;- DF %&gt;%\n  group_by(roy2) %&gt;%\n  summarise(total_pumping = sum(total_pumping, na.rm = TRUE), .groups = \"drop\")\ny_max_exempt &lt;- max(year_totals_exempt$total_pumping, na.rm = TRUE)\n\nplot_exempt &lt;- Data %&gt;% dygraph(group = \"a\") %&gt;%\n  dyStackedBarGroup(c(\"W218\",\"W219\",\"W330\",\"W332\")) %&gt;%\n  dyBarChart() %&gt;%\n  dyAxis(\"y\", label = \"Total Annual Pumping (AF)\", axisLabelWidth = 70)\n\nif (is.finite(y_max_exempt)) {\n  plot_exempt &lt;- plot_exempt %&gt;% dyAxis(\"y\", valueRange = c(0, y_max_exempt * 1.05))\n}\n\nplot_exempt\n\n\n\n\n\n\nFigure 1: hatchery wells 330/332 and exempt wells 218/219\n\n\n\nBig Pine Pumping Totals\n\ncodelinked_wells &lt;- c(\"W210\",\"W378\",\"W379\",\"W389\",\"W220\",\"W229\",\"W374\",\"W375\",\"W222\",\"W223\",\"W231\",\"W232\",\"W331\",\"W218\",\"W219\",\"W330\",\"W332\")\n\nDF &lt;- tm2 %&gt;%\n  filter(staid %in% linked_wells) %&gt;%\n  mutate(read = if_else(read == -777, 0, read)) %&gt;%\n  group_by(roy, staid) %&gt;%\n  summarise(total_pumping = sum(read, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  mutate(roy2 = make_date(roy, 4, 1))\n\nDF &lt;- pad_series_bounds(DF, \"roy2\", \"staid\", months_start = 6, months_end = 18)\n\nData &lt;- do.call(merge, lapply(split(DF, DF$staid), tozoo))\nyear_totals_bp &lt;- DF %&gt;%\n  group_by(roy2) %&gt;%\n  summarise(total_pumping = sum(total_pumping, na.rm = TRUE), .groups = \"drop\")\ny_max_bp &lt;- max(year_totals_bp$total_pumping, na.rm = TRUE)\n\nplot_bp &lt;- Data %&gt;% dygraph(group = \"a\") %&gt;%\n  dyStackedBarGroup(c(\"W210\",\"W378\",\"W379\",\"W389\",\"W220\",\"W229\",\"W374\",\"W375\",\"W222\",\"W223\",\"W231\",\"W232\",\"W331\",\"W218\",\"W219\",\"W330\",\"W332\")) %&gt;%\n  dyBarChart() %&gt;%\n  dyAxis(\"y\", label = \"Total Annual Pumping (AF)\", axisLabelWidth = 70)\n\nif (is.finite(y_max_bp)) {\n  plot_bp &lt;- plot_bp %&gt;% dyAxis(\"y\", valueRange = c(0, y_max_bp * 1.05))\n}\n\nplot_bp\n\n\nBig Pine Wellfield Pumping\n\n\nTaboose/Aberdeen Monitoring Site #3 (TA3)\n\ncodeplot_linked_wells(tm2, \"TA3\", linked_wells_sites)\n\n\n\n\n\nTaboose/Aberdeen Monitoring Site #4 (TA4)\n\ncodeplot_linked_wells(tm2, \"TA4\", linked_wells_sites)\n\n\n\n\n\nTaboose/Aberdeen Monitoring Site #5 (TA5)\n\ncodeplot_linked_wells_single(tm2, \"TA5\", linked_wells_sites)\n\n\n\n\n\nTaboose/Aberdeen Monitoring Site #6 (TA6)\n\ncodeplot_linked_wells(tm2, \"TA6\", linked_wells_sites)\n\n\n\n\n\nTaboose/Aberdeen Wellfield Total Pumping\n\ncodeplot_wellfield_total(\n  tm2,\n  field_sites = c(\"TA3\", \"TA4\", \"TA5\", \"TA6\"),\n  linked_wells_sites = linked_wells_sites,\n  title = \"Taboose/Aberdeen Wellfield Total Pumping\"\n)\n\n\n\n\n\nThibaut/Sawmill Monitoring Site #1 (TS1)\n\ncodeplot_linked_wells_single(tm2, \"TS1\", linked_wells_sites)\n\n\n\n\n\nThibaut/Sawmill Monitoring Site #2 (TS2)\n\ncodeplot_linked_wells_single(tm2, \"TS2\", linked_wells_sites)\n\n\n\n\n\nThibaut/Sawmill Monitoring Site #3 (TS3)\n\ncodeplot_linked_wells(tm2, \"TS3\", linked_wells_sites)\n\n\n\n\n\nThibaut/Sawmill Monitoring Site #4 (TS4)\n\ncodeplot_linked_wells(tm2, \"TS4\", linked_wells_sites)\n\n\n\n\n\nThibaut/Sawmill Wellfield Total Pumping\n\ncodeplot_wellfield_total(\n  tm2,\n  field_sites = c(\"TS1\", \"TS2\", \"TS3\", \"TS4\"),\n  linked_wells_sites = linked_wells_sites,\n  title = \"Thibaut/Sawmill Wellfield Total Pumping\"\n)\n\n\n\n\n\nIndependence/Oak Monitoring Site #1 (IO1)\n\ncodeplot_linked_wells(tm2, \"IO1\", linked_wells_sites)\n\n\n\n\n\nIndependence/Oak Monitoring Site #2 (IO2)\n\ncodeplot_linked_wells_single(tm2, \"IO2\", linked_wells_sites)\n\n\n\n\n\nIndependence/Oak Wellfield Total Pumping\n\ncodeplot_wellfield_total(\n  tm2,\n  field_sites = c(\"IO1\", \"IO2\"),\n  linked_wells_sites = linked_wells_sites,\n  title = \"Independence/Oak Wellfield Total Pumping\"\n)\n\n\n\n\n\nSymmes/Shepherd Monitoring Site #1 (SS1)\n\ncodeplot_linked_wells(tm2, \"SS1\", linked_wells_sites)\n\n\n\n\n\nSymmes/Shepherd Monitoring Site #2 (SS2)\n\ncodeplot_linked_wells(tm2, \"SS2\", linked_wells_sites)\n\n\n\n\n\nSymmes/Shepherd Monitoring Site #3 (SS3)\n\ncodeplot_linked_wells(tm2, \"SS3\", linked_wells_sites)\n\n\n\n\n\nSymmes/Shepherd Monitoring Site #4 (SS4)\n\ncodeplot_linked_wells(tm2, \"SS4\", linked_wells_sites)\n\n\n\n\n\nSymmes/Shepherd Wellfield Total Pumping\n\ncodeplot_wellfield_total(\n  tm2,\n  field_sites = c(\"SS1\", \"SS2\", \"SS3\", \"SS4\"),\n  linked_wells_sites = linked_wells_sites,\n  title = \"Symmes/Shepherd Wellfield Total Pumping\"\n)\n\n\n\n\n\nBairs/Georges Monitoring Site #2 (BG2)\n\ncodeplot_linked_wells(tm2, \"BG2\", linked_wells_sites)\n\n\n\n\n\nBairs/Georges Wellfield Total Pumping\n\ncodeplot_wellfield_total(\n  tm2,\n  field_sites = c(\"BG2\"),\n  linked_wells_sites = linked_wells_sites,\n  title = \"Bairs/Georges Wellfield Total Pumping\"\n)"
  },
  {
    "objectID": "package/NEWS.html",
    "href": "package/NEWS.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\n\nhydrodata 0.1.0\n\nInitial package prototype.\nAdded manifest-driven dataset listing and download helpers.\nAdded vignette linking to the DTW and flow reports."
  },
  {
    "objectID": "index.html#data-combination-and-daily-harmonization",
    "href": "index.html#data-combination-and-daily-harmonization",
    "title": "Flow Data",
    "section": "Data combination and daily harmonization",
    "text": "Data combination and daily harmonization\n\ntestwellupdate# rename the columns\n# clean up the date with formal date specification\ntestwell.up &lt;- try %&gt;% select(-date, -datetime) %&gt;% rename(date = date.y.m.d) %&gt;% mutate(source = \"DWP\")  \n# head(testwell.up)\n\n\n\nappend updates to master database## Append updates to master\ntestwells.combined &lt;- bind_rows(hist, testwell.up) \n\n# head(testwells.combined)\n# 1,145,360 records going back to 1971\n\n# testwells.combined %&gt;% n_distinct(staid)\n# testwells.combined %&gt;% distinct(staid) %&gt;% nrow()\n\n\n\n\n\n\nMetric\nValue\n\n\n\nAnnual update rows\n89,289\n\n\nAnnual update staids\n750\n\n\nActive database rows\n1,324,540\n\n\nActive database staids\n1,381"
  },
  {
    "objectID": "index.html#raw-input-coverage-1",
    "href": "index.html#raw-input-coverage-1",
    "title": "Flow Data",
    "section": "Raw input coverage",
    "text": "Raw input coverage\nThe table below summarizes the raw input coverage for the current and prior water years. Use this to confirm record counts and date ranges before merging with historical totals.\n#| code-fold: true\n#| code-summary: \"raw input coverage\"\n\nraw_flow_coverage &lt;- tibble(\n  File = c(basename(file_path_flow), basename(file_path_flow_prev)),\n  Records = c(nrow(ann.update2), nrow(ann.update_prev2)),\n  Unique_staids = c(\n    dplyr::n_distinct(ann.update2$staid),\n    dplyr::n_distinct(ann.update_prev2$staid)\n  ),\n  Date_start = c(\n    min(ymd_hms(ann.update2$date), na.rm = TRUE),\n    if (nrow(ann.update_prev2) &gt; 0) min(ymd_hms(ann.update_prev2$date), na.rm = TRUE) else as.POSIXct(NA)\n  ),\n  Date_end = c(\n    max(ymd_hms(ann.update2$date), na.rm = TRUE),\n    if (nrow(ann.update_prev2) &gt; 0) max(ymd_hms(ann.update_prev2$date), na.rm = TRUE) else as.POSIXct(NA)\n  )\n)\n\nknitr::kable(raw_flow_coverage)\n#| code-fold: true\n#| code-summary: \"date columns\"\n\nann.update2$datetime &lt;- ymd_hms(ann.update2$date)\n\n\nann.update3&lt;-ann.update2 %&gt;% \n  mutate(year = year(datetime),\n         month = month(datetime),\n         month_abbr = month(datetime, label = TRUE, abbr = TRUE),\n         day = mday(datetime),\n         date.y.m.d = make_date(year, month,day))\n\nann.update4&lt;-ann.update3 %&gt;% \n  select(-date) %&gt;% \n  rename(date = date.y.m.d) %&gt;% \n  left_join(staidlist, by = 'staid') %&gt;% \n  select(staid,description,read,date,year,month,month_abbr) \n\nann.update5 &lt;- ann.update4 %&gt;% \n  mutate(wy = case_when(month &gt;= 10 ~ year + 1,\n                        month &lt;= 9 ~ year),\n         roy = case_when(month &lt;= 3 ~ year - 1,\n                         month &gt;= 4 ~ year),\n         irrag = case_when(month %in% c(4,5,6,7,8,9) ~ year))\n\n#| code-fold: true\n#| code-summary: \"summary stations\"\n\nif (nrow(sum_stations) &gt; 0) {\n  sstations &lt;- sum_stations %&gt;% \n    gather(staid,read,-date) %&gt;% \n    left_join(staidlist, by = 'staid') %&gt;% \n    select(-desc_id) %&gt;% \n    mutate(date = as.Date(date),\n           datetime = as.Date(date),\n           month = month(datetime),\n           year = year(datetime),\n           month_abbr = month(datetime, label = TRUE, abbr = TRUE))\n} else {\n  sstations &lt;- ann.update4 %&gt;% slice(0)\n}\n#| code-fold: true\n#| code-summary: \"split into ovga and ic updates\"\n\nupdate.merged.ic &lt;- bind_rows(sstations,ann.update4)\nupdate.merged &lt;- ann.update4"
  },
  {
    "objectID": "index.html#icwd-flow-export",
    "href": "index.html#icwd-flow-export",
    "title": "Flow Data",
    "section": "ICWD flow export",
    "text": "ICWD flow export\n#| code-fold: true\n#| code-summary: \"IC date columns\"\n\nupdate.merged.ic &lt;- update.merged.ic %&gt;% \n  mutate(wy = case_when(month &gt;= 10 ~ year + 1,\n                        month &lt;= 9 ~ year),\n         roy = case_when(month &lt;= 3 ~ year - 1,\n                         month &gt;= 4 ~ year),\n         irrag = case_when(month %in% c(4,5,6,7,8,9) ~ year))\n#| code-fold: true\n#| code-summary: \"update IC DB\"\n\ntotals_means &lt;- bind_rows(update.merged.ic, monthlies) %&gt;%\n  mutate(date = as.Date(date))\n#| code-fold: true\n#| code-summary: \"write updated IC DB\"\n\ntotals_means %&gt;% write_csv(here('data','hydro','totals_means_thru_sep_2025.csv'))\nout_icwd &lt;- here(\"output\", \"2025wy\", \"ICWD\")\ndir.create(out_icwd, recursive = TRUE, showWarnings = FALSE)\ntotals_means %&gt;% write_csv(file.path(out_icwd, \"totals_means_thru_sep_2025.csv\"))"
  },
  {
    "objectID": "index.html#ovga-flow-export",
    "href": "index.html#ovga-flow-export",
    "title": "Flow Data",
    "section": "OVGA flow export",
    "text": "OVGA flow export\nFlow exports are derived from the monthly flow records after joining flow metadata and filtering to valid OVGA monitoring points. The output is formatted to the OVGA surface-water import template. The OVGA template reuses the “WellName” column for both wells and gages; in the flow export that column holds gage IDs (e.g. SW0373), not well names.\n#| code-fold: true\n#| code-summary: \"filter no value -777\"\n\ntm &lt;- ann.update5 %&gt;% filter(read != -777)\n#| code-fold: true\n#| code-summary: \"split flow vs production\"\n\nnormalize_flow_staid &lt;- function(x) {\n  ifelse(str_detect(x, \"^0\"), str_replace(x, \"^0+\", \"\"), x)\n}\n\nflowdf &lt;- tm %&gt;% \n  filter(!str_detect(staid, \"[[:alpha:]]\")) %&gt;%\n  mutate(staid = normalize_flow_staid(staid))\n\nflow_ovga &lt;- flowdf %&gt;%\n  left_join(flow.meta, by = 'staid') %&gt;%\n  filter(!is.na(mon_pt_name), mon_pt_name != \"\")\n\nproddf &lt;- tm %&gt;% filter(str_detect(staid, \"[[:alpha:]]\"))\n#| code-fold: true\n#| code-summary: \"ovga flow columns\"\n\nsw.flow &lt;- flow_ovga  %&gt;% \n  mutate(WellName = mon_pt_name,\n         FlowDate = date,\n         FlowRateAcFtPM = read,\n         FlowRateCFS = \"\",\n         FlowRateGPM = \"\") %&gt;% \n  select(WellName,FlowDate,FlowRateAcFtPM, FlowRateCFS, FlowRateGPM)\n\nsw.flow %&gt;%\n  datatable(\n    options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE),\n    class = \"compact stripe\"\n  )\n  \n#| code-fold: true\n#| code-summary: \"find/remove duplicates\"\n\ndupes &lt;- sw.flow %&gt;% get_dupes() \n\nswflow2 &lt;- sw.flow %&gt;% anti_join(dupes)\n#| code-fold: true\n#| code-summary: \"write ovga flow\"\n#| eval: false\n\nout_ovga &lt;- here(\"output\", \"2025wy\", \"OVGA\")\ndir.create(out_ovga, recursive = TRUE, showWarnings = FALSE)\nswflow2 %&gt;% write_csv(file.path(out_ovga, paste0(\"ovga_swflow_import_wy\", wy_short, \".csv\")))\n#| code-fold: true\n#| code-summary: \"OVGA flow import metrics\"\n\nflow_import_metrics &lt;- tibble(\n  Metric = c(\n    \"Flow records in upload\",\n    \"Unique monitoring points\",\n    \"Date range\"\n  ),\n  Value = c(\n    nrow(swflow2),\n    dplyr::n_distinct(swflow2$WellName),\n    paste0(min(swflow2$FlowDate, na.rm = TRUE), \" to \", max(swflow2$FlowDate, na.rm = TRUE))\n  )\n) %&gt;% mutate(Value = format(Value, big.mark = \",\"))\n\nknitr::kable(flow_import_metrics)\nFlow export comparison (last year vs current)\nThis comparison highlights which flow gages were added or removed from the OVGA export between WY2024 and WY2025.\nflow_export_last_path &lt;- here(\"output\", \"ovga_swflow_import_wy24.csv\")\nflow_export_last &lt;- if (file.exists(flow_export_last_path)) {\n  read_csv(flow_export_last_path, show_col_types = FALSE) %&gt;% distinct(WellName)\n} else {\n  tibble(WellName = character())\n}\n\nflow_export_current &lt;- swflow2 %&gt;% distinct(WellName)\n\nflow_export_missing &lt;- flow_export_last %&gt;% anti_join(flow_export_current, by = \"WellName\")\nflow_export_new &lt;- flow_export_current %&gt;% anti_join(flow_export_last, by = \"WellName\")\n\nDT::datatable(\n  flow_export_missing,\n  options = list(pageLength = 10, lengthChange = TRUE),\n  caption = \"Flow gages in WY2024 export but missing in WY2025 export\"\n)\n\nDT::datatable(\n  flow_export_new,\n  options = list(pageLength = 10, lengthChange = TRUE),\n  caption = \"Flow gages in WY2025 export but not in WY2024 export\"\n)"
  },
  {
    "objectID": "index.html#ovga-production-export",
    "href": "index.html#ovga-production-export",
    "title": "Flow Data",
    "section": "OVGA production export",
    "text": "OVGA production export\nProduction exports are derived from monthly production records after joining production metadata and filtering to valid OVGA monitoring points. Missing method values are defaulted to “Unknown” to satisfy the OVGA template.\n#| code-fold: true\n#| code-summary: \"ovga production columns\"\n\nprod_ovga &lt;- proddf %&gt;%\n  left_join(production.meta, by = c('staid' = 'mon_pt_name')) %&gt;%\n  semi_join(ovga_points, by = c(\"staid\" = \"mon_pt_name\"))\n\ntm.well.flow &lt;- prod_ovga %&gt;% \n  mutate(WellName = staid,\n         StartDate = date,\n         EndDate = ceiling_date(date,'month'),\n         AgUsageAF = '',\n         MIUsageAF = read,\n         TotalUsageAF = read,\n         Method = if_else(is.na(method) | method == \"\", \"Unknown\", method),\n         Notes = '') %&gt;% \n  select(WellName,StartDate,EndDate, AgUsageAF, MIUsageAF, TotalUsageAF, Method, Notes)\ntm.well.flow %&gt;%\n  datatable(\n    options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE),\n    class = \"compact stripe\"\n  )\n#| code-fold: true\n#| code-summary: \"find/replace duplicates\"\n\ndupeswell &lt;- tm.well.flow %&gt;% get_dupes()\nif (nrow(dupeswell) == 0) {\n  cat(\"No duplicates found.\\n\")\n} else {\n  cat(\"Duplicate rows found: \", nrow(dupeswell), \"\\n\")\n  dupeswell\n}\n#| code-fold: true\n#| code-summary: \"write ovga production\"\n#| label: ovga-production-export\n#| eval: false\n\nout_ovga &lt;- here(\"output\", \"2025wy\", \"OVGA\")\ndir.create(out_ovga, recursive = TRUE, showWarnings = FALSE)\ntm.well.flow %&gt;% write_csv(file.path(out_ovga, paste0(\"ovga_production_import_wy\", wy_range, \".csv\")))\nwritexl::write_xlsx(tm.well.flow, file.path(out_ovga, paste0(\"ovga_production_import_wy\", wy_range, \".xlsx\")))\n#| code-fold: true\n#| code-summary: \"OVGA production import metrics\"\n\nproduction_import_metrics &lt;- tibble(\n  Metric = c(\n    \"Production records in upload\",\n    \"Unique production wells\",\n    \"Date range\"\n  ),\n  Value = c(\n    nrow(tm.well.flow),\n    dplyr::n_distinct(tm.well.flow$WellName),\n    paste0(min(tm.well.flow$StartDate, na.rm = TRUE), \" to \", max(tm.well.flow$EndDate, na.rm = TRUE))\n  )\n) %&gt;% mutate(Value = format(Value, big.mark = \",\"))\n\nknitr::kable(production_import_metrics)\nProduction export comparison (last year vs current)\nThis comparison highlights which production wells were added or removed from the OVGA export between WY2024 and WY2025.\nproduction_export_last_path &lt;- here(\"output\", \"ovga_production_import_wy23-24.csv\")\nproduction_export_last &lt;- if (file.exists(production_export_last_path)) {\n  read_csv(production_export_last_path, show_col_types = FALSE) %&gt;% distinct(WellName)\n} else {\n  tibble(WellName = character())\n}\n\nproduction_export_current &lt;- tm.well.flow %&gt;% distinct(WellName)\n\nproduction_export_missing &lt;- production_export_last %&gt;% anti_join(production_export_current, by = \"WellName\")\nproduction_export_new &lt;- production_export_current %&gt;% anti_join(production_export_last, by = \"WellName\")\n\nDT::datatable(\n  production_export_missing,\n  options = list(pageLength = 10, lengthChange = TRUE),\n  caption = \"Production wells in WY2024 export but missing in WY2025 export\"\n)\n\nDT::datatable(\n  production_export_new,\n  options = list(pageLength = 10, lengthChange = TRUE),\n  caption = \"Production wells in WY2025 export but not in WY2024 export\"\n)\nRaw data exclusions (last year vs current)\nThese tables show staids present in the raw input data but excluded from the export, which helps isolate metadata gaps or OVGA list mismatches.\nraw_flow_current &lt;- ann.update2 %&gt;%\n  filter(!str_detect(staid, \"[[:alpha:]]\")) %&gt;%\n  mutate(staid = normalize_flow_staid(staid))\n\nraw_flow_prev &lt;- ann.update_prev2 %&gt;%\n  filter(!str_detect(staid, \"[[:alpha:]]\")) %&gt;%\n  mutate(staid = normalize_flow_staid(staid))\n\nraw_prod_current &lt;- ann.update2 %&gt;%\n  filter(str_detect(staid, \"[[:alpha:]]\"))\n\nraw_prod_prev &lt;- ann.update_prev2 %&gt;%\n  filter(str_detect(staid, \"[[:alpha:]]\"))\n\nraw_flow_current_joined &lt;- raw_flow_current %&gt;%\n  left_join(flow.meta, by = \"staid\")\n\nraw_flow_prev_joined &lt;- raw_flow_prev %&gt;%\n  left_join(flow.meta, by = \"staid\")\n\nraw_flow_excluded_current &lt;- raw_flow_current_joined %&gt;%\n  filter(is.na(mon_pt_name) | !(mon_pt_name %in% flow_export_current$WellName)) %&gt;%\n  distinct(staid, mon_pt_name) %&gt;%\n  arrange(staid)\n\nraw_flow_excluded_prev &lt;- raw_flow_prev_joined %&gt;%\n  filter(is.na(mon_pt_name) | !(mon_pt_name %in% flow_export_last$WellName)) %&gt;%\n  distinct(staid, mon_pt_name) %&gt;%\n  arrange(staid)\n\nraw_prod_excluded_current &lt;- raw_prod_current %&gt;%\n  distinct(staid) %&gt;%\n  filter(!staid %in% production_export_current$WellName) %&gt;%\n  arrange(staid)\n\nraw_prod_excluded_prev &lt;- raw_prod_prev %&gt;%\n  distinct(staid) %&gt;%\n  filter(!staid %in% production_export_last$WellName) %&gt;%\n  arrange(staid)\n\nDT::datatable(\n  raw_flow_excluded_prev,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE),\n  caption = \"Flow staids in WY2024 raw data excluded from WY2024 export\"\n)\n\nDT::datatable(\n  raw_flow_excluded_current,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE),\n  caption = \"Flow staids in WY2025 raw data excluded from WY2025 export\"\n)\n\nDT::datatable(\n  raw_prod_excluded_prev,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE),\n  caption = \"Production staids in WY2024 raw data excluded from WY2024 export\"\n)\n\nDT::datatable(\n  raw_prod_excluded_current,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE),\n  caption = \"Production staids in WY2025 raw data excluded from WY2025 export\"\n)\nRemoved staids not on the basin list are excluded from OVGA exports and reflected in the raw‑data exclusion tables above.\nOVGA flow and production exclusions (download)\n#| code-fold: true\n#| code-summary: \"flow/production staids excluded from OVGA exports\"\n\nflow_exclusions &lt;- flowdf %&gt;%\n  left_join(flow.meta, by = \"staid\") %&gt;%\n  filter(is.na(mon_pt_name) | mon_pt_name == \"\") %&gt;%\n  group_by(staid) %&gt;%\n  summarise(\n    records = n(),\n    first_date = min(date, na.rm = TRUE),\n    last_date = max(date, na.rm = TRUE),\n    mon_pt_name = dplyr::first(mon_pt_name),\n    .groups = \"drop\"\n  ) %&gt;%\n  left_join(staidlist, by = \"staid\") %&gt;%\n  mutate(\n    dataset = \"flow\",\n    reason = \"Missing flow metadata mapping (Flows.csv)\"\n  ) %&gt;%\n  select(\n    dataset,\n    staid,\n    description,\n    records,\n    first_date,\n    last_date,\n    mon_pt_name,\n    reason\n  ) %&gt;%\n  arrange(staid)\n\nprod_exclusions &lt;- proddf %&gt;%\n  anti_join(ovga_points, by = c(\"staid\" = \"mon_pt_name\")) %&gt;%\n  left_join(production.meta, by = c(\"staid\" = \"mon_pt_name\")) %&gt;%\n  group_by(staid) %&gt;%\n  summarise(\n    records = n(),\n    first_date = min(date, na.rm = TRUE),\n    last_date = max(date, na.rm = TRUE),\n    method = dplyr::first(method),\n    .groups = \"drop\"\n  ) %&gt;%\n  left_join(staidlist, by = \"staid\") %&gt;%\n  mutate(\n    dataset = \"production\",\n    reason = \"Not in OVGA monitoring points list\"\n  ) %&gt;%\n  select(\n    dataset,\n    staid,\n    description,\n    records,\n    first_date,\n    last_date,\n    method,\n    reason\n  ) %&gt;%\n  arrange(staid)\n\nout_ovga &lt;- here(\"output\", \"2025wy\", \"OVGA\")\ndir.create(out_ovga, recursive = TRUE, showWarnings = FALSE)\n\nflow_exclusions %&gt;%\n  write_csv(file.path(out_ovga, paste0(\"ovga_flow_exclusions_wy\", wy_year, \".csv\")))\nwritexl::write_xlsx(flow_exclusions, file.path(out_ovga, paste0(\"ovga_flow_exclusions_wy\", wy_year, \".xlsx\")))\nprod_exclusions %&gt;%\n  write_csv(file.path(out_ovga, paste0(\"ovga_production_exclusions_wy\", wy_year, \".csv\")))\nwritexl::write_xlsx(prod_exclusions, file.path(out_ovga, paste0(\"ovga_production_exclusions_wy\", wy_year, \".xlsx\")))\n\ndtw_exclusions_path &lt;- file.path(out_ovga, \"ovga_dtw_exclusions_wy2025.csv\")\nif (file.exists(dtw_exclusions_path)) {\n  dtw_exclusions &lt;- read_csv(dtw_exclusions_path, show_col_types = FALSE)\n  ovga_exclusions &lt;- bind_rows(dtw_exclusions, flow_exclusions, prod_exclusions)\n  ovga_exclusions %&gt;%\n    write_csv(file.path(out_ovga, paste0(\"ovga_exclusions_wy\", wy_year, \".csv\")))\n  writexl::write_xlsx(ovga_exclusions, file.path(out_ovga, paste0(\"ovga_exclusions_wy\", wy_year, \".xlsx\")))\n}\n\nDT::datatable(\n  flow_exclusions,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE),\n  class = \"compact stripe\",\n  caption = \"Flow staids excluded from OVGA export (WY2025)\"\n)\n\nDT::datatable(\n  prod_exclusions,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE),\n  class = \"compact stripe\",\n  caption = \"Production staids excluded from OVGA export (WY2025)\"\n)"
  },
  {
    "objectID": "index.html#totals-and-means---summary-stations-requested",
    "href": "index.html#totals-and-means---summary-stations-requested",
    "title": "Flow Data",
    "section": "Totals and Means - summary stations requested",
    "text": "Totals and Means - summary stations requested\nSummary-station series (OVR, OVPW, etc.) are populated from the summary stations file. Until summary_stations24-25.csv is delivered, these plots will extend through WY2024.\nOVR Owens Valley Runoff\n```{r OVR, fig.width = 10, fig.height = 3, fig.fullwidth = TRUE, fig.cap = “Owens Valley Runoff”, warning=FALSE}\ntm2 &lt;- totals_means monthly_uses_syncplot(staid_p = “OVR” ,data = tm2, group_name = ‘ov’)\n\n### OVPW Owens Valley Pumped Water\n\n```{r OVPW, fig.width = 10, fig.height = 3, fig.fullwidth = TRUE, fig.cap = \"Owens Valley Pumped Water\", warning=FALSE}\n\nmonthly_uses_syncplot(staid_p = \"OVPW\" ,data = tm2, group_name = 'ov')\nFTC L.A.A. Total Flow to the City\n```{r FTC, fig.width = 10, fig.height = 3, fig.fullwidth = TRUE, fig.cap = “LAA Total Flow to the City”, warning=FALSE}\nmonthly_uses_syncplot(staid_p = “FTC” ,data = tm2, group_name = ‘ov’)\n\n### LOLU Lower Owens River Project -- Lakes and Ponds Use\n\n```{r LOLU, fig.width = 10, fig.height = 3, fig.fullwidth = TRUE, fig.cap = \"Lower Owens River Project – Lakes and Ponds Use\", warning=FALSE}\n\nmonthly_uses_syncplot(staid_p = \"LOLU\" ,data = tm2, group_name = 'ov')\nLOOU Lower Owens River Project – Operations\n```{r LOOU, fig.width = 10, fig.height = 3, fig.fullwidth = TRUE, fig.cap = “Lower Owens River Project – Operations”, warning=FALSE}\nmonthly_uses_syncplot(staid_p = “LOOU” ,data = tm2, group_name = ‘ov’)\n\n### LORPDU Lower Owens River -- Delta Uses\n\n```{r LORPDU, fig.width = 10, fig.height = 3, fig.fullwidth = TRUE, fig.cap = \"Lower Owens River – Delta Uses\", warning=FALSE}\n\nmonthly_uses_syncplot(staid_p = \"LORPDU\" ,data = tm2, group_name = 'ov')\nLORPRU Lower Owens River – River Uses\n```{r LORPRU, fig.width = 10, fig.height = 3, fig.fullwidth = TRUE, fig.cap = “Lower Owens River – River Uses”, warning=FALSE}\nmonthly_uses_syncplot(staid_p = “LORPRU” ,data = tm2, group_name = ‘ov’)\n\n### LORPTU Lower Owens River Project Total Uses\n\n```{r LORPTU, fig.width = 10, fig.height = 3, fig.fullwidth = TRUE, fig.cap = \"Lower Owens River Project Total Uses\", warning=FALSE}\n\nmonthly_uses_syncplot(staid_p = \"LORPTU\" ,data = tm2, group_name = 'ov')\nLOWU Lower Owens River Project – Waterfowl Uses\n```{r LOWU, fig.width = 10, fig.height = 3, fig.fullwidth = TRUE, fig.cap = “Lower Owens River Project – Waterfowl Uses”, warning=FALSE}\nmonthly_uses_syncplot(staid_p = “LOWU” ,data = tm2, group_name = ‘ov’)\n\n### MBR Mono Basin Runoff\n\n```{r MBR, fig.width = 10, fig.height = 3, fig.fullwidth = TRUE, fig.cap = \"Mono Basin Runoff\", warning=FALSE}\n\nmonthly_uses_syncplot(staid_p = \"MBR\" ,data = tm2, group_name = 'ov')\nMTWP Mono Tunnel at West Portal\n```{r MTWP, fig.width = 10, fig.height = 3, fig.fullwidth = TRUE, fig.cap = “Mono Tunnel at West Portal”, warning=FALSE}\nmonthly_uses_syncplot(staid_p = “MTWP” ,data = tm2, group_name = ‘ov’)\n\n### OLTU Owens Lake Total Uses\n\n```{r OLTU, fig.width = 10, fig.height = 3, fig.fullwidth = TRUE, fig.cap = \"Owens Lake Total Uses\", warning=FALSE}\n\nmonthly_uses_syncplot(staid_p = \"OLTU\" ,data = tm2, group_name = 'ov')\nOVFG Owens Valley Flowing Groundwater\n```{r OVFG, fig.width = 10, fig.height = 3, fig.fullwidth = TRUE, fig.cap = “Owens Valley Flowing Groundwater”, warning=FALSE}\nmonthly_uses_syncplot(staid_p = “OVFG” ,data = tm2, group_name = ‘ov’)\n\n### OVGR Owens Valley Groundwater Recharge\n\n```{r OVGR, fig.width = 10, fig.height = 3, fig.fullwidth = TRUE, fig.cap = \"Owens Valley Groundwater Recharge\", warning=FALSE}\n\nmonthly_uses_syncplot(staid_p = \"OVGR\" ,data = tm2, group_name = 'ov')\nOVIR Owens Valley Irrigation\n```{r OVIR, fig.width = 10, fig.height = 3, fig.fullwidth = TRUE, fig.cap = “Owens Valley Irrigation”, warning=FALSE}\nmonthly_uses_syncplot(staid_p = “OVIR” ,data = tm2, group_name = ‘ov’)\n\n### SHTO South Haiwee Total Outflow (1+2+3+BP)\n\n```{r SHTO, fig.width = 10, fig.height = 3, fig.fullwidth = TRUE, fig.cap = \"South Haiwee Total Outflow (1+2+3+BP)\", warning=FALSE}\n\nmonthly_uses_syncplot(staid_p = \"SHTO\" ,data = tm2, group_name = 'ov')"
  },
  {
    "objectID": "index.html#stream-flow",
    "href": "index.html#stream-flow",
    "title": "Flow Data",
    "section": "Stream flow",
    "text": "Stream flow\nTop 10 stream gages by WY2025 volume (water year Oct-Sep)\n```{r top-streams, fig.width = 7, fig.height = 4.5, fig.fullwidth = TRUE, warning=FALSE} flow_wy &lt;- flowdf %&gt;% mutate(wy = if_else(month &gt;= 10, year + 1, year))\ntop_streams &lt;- flow_wy %&gt;% filter(wy == wy_year) %&gt;% group_by(staid) %&gt;% summarise(total_af = sum(read, na.rm = TRUE), .groups = “drop”) %&gt;% arrange(desc(total_af)) %&gt;% slice_head(n = 10) %&gt;% left_join(flow.meta, by = “staid”)\ntop_streams &lt;- top_streams %&gt;% mutate(display_name = if_else(is.na(mon_pt_name) | mon_pt_name == ““, staid, mon_pt_name))\nplots &lt;- purrr::map2(top_streamsstaid, top_streamsdisplay_name, ~{ plot_title &lt;- paste0(.y, ” (“, .x,”)“) htmltools::tagList( htmltools::tags$h4(plot_title), monthly_flow_syncplot_staid(staid_p = .x, data = totals_means, group_name =”a”, title = plot_title) ) })\nhtmltools::tagList(plots)\n\n## Pumping\n\nRunoff year (Apr-Mar) pumping totals are reported below. Water year (Oct-Sep) is used for the flow series above. RY2025 totals are partial because Oct–Mar 2025–26 data have not yet been delivered.\n\n```{r}\ntozoo &lt;- function(x) zoo(x$total_pumping, x$roy2)\ndyMultiColumn &lt;- function(dygraph) {\n  dyPlotter(dygraph = dygraph,\n            name = \"MultiColumn\",\n            path = system.file(\"plotters/multicolumn.js\",\n                               package = \"dygraphs\"))\n}\n\nplot_wellfield_total &lt;- function(data, field_sites, linked_wells_sites, title, value_range = NULL) {\n  linked_wells &lt;- linked_wells_sites %&gt;%\n    filter(Site %in% field_sites) %&gt;%\n    pull(Linked_Well) %&gt;%\n    unique()\n\n  if (length(linked_wells) == 0) {\n    return(NULL)\n  }\n\n  df &lt;- data %&gt;%\n    filter(staid %in% linked_wells) %&gt;%\n    mutate(read = if_else(read == -777, 0, read)) %&gt;%\n    group_by(roy, staid) %&gt;%\n    summarise(total_pumping = sum(read, na.rm = TRUE), .groups = \"drop\") %&gt;%\n    mutate(roy2 = make_date(roy, 4, 1))\n\n  df &lt;- pad_series_bounds(df, \"roy2\", \"staid\", months_start = 6, months_end = 18)\n\n  year_totals &lt;- df %&gt;%\n    group_by(roy2) %&gt;%\n    summarise(total_pumping = sum(total_pumping, na.rm = TRUE), .groups = \"drop\")\n  y_max &lt;- max(year_totals$total_pumping, na.rm = TRUE)\n\n  plot_data &lt;- do.call(merge, lapply(split(df, df$staid), tozoo))\n  plot &lt;- plot_data %&gt;%\n    dygraph(main = title, group = \"a\") %&gt;%\n    dyStackedBarGroup(linked_wells) %&gt;%\n    dyBarChart() %&gt;%\n    dyAxis(\"y\", label = \"Total Annual Pumping (AF)\", axisLabelWidth = 70)\n\n  if (is.finite(y_max)) {\n    plot &lt;- plot %&gt;% dyAxis(\"y\", valueRange = c(0, y_max * 1.05))\n  }\n\n  if (!is.null(value_range)) {\n    plot &lt;- plot %&gt;% dyAxis(\"y\", valueRange = value_range)\n  }\n\n  plot\n}\n\ncompute_linked_seasonal &lt;- function(data, linked_wells_sites, group_map, group_col, target_year = 2025) {\n  base &lt;- data %&gt;%\n    filter(staid %in% linked_wells_sites$Linked_Well) %&gt;%\n    mutate(\n      read = if_else(read &lt; 0, 0, read),\n      date = as.Date(date),\n      year = year(date),\n      month = month(date),\n      wy = if_else(month &gt;= 10, year + 1, year),\n      runoff_year = if_else(month &gt;= 4, year, year - 1),\n      season = case_when(\n        month %in% 4:9 ~ \"Apr-Sep\",\n        month %in% c(10, 11, 12, 1, 2, 3) ~ \"Oct-Mar\",\n        TRUE ~ NA_character_\n      )\n    ) %&gt;%\n    left_join(group_map, by = c(\"staid\" = \"Linked_Well\")) %&gt;%\n    filter(!is.na(.data[[group_col]]))\n\n  seasonal_wy &lt;- base %&gt;%\n    group_by(.data[[group_col]], wy, season) %&gt;%\n    summarise(total_pumping = sum(read, na.rm = TRUE), .groups = \"drop\") %&gt;%\n    pivot_wider(names_from = season, values_from = total_pumping) %&gt;%\n    rename(Group = !!sym(group_col), WY = wy) %&gt;%\n    arrange(Group, WY)\n\n  runoff_ry &lt;- base %&gt;%\n    group_by(.data[[group_col]], runoff_year) %&gt;%\n    summarise(`Apr-Mar` = sum(read, na.rm = TRUE), .groups = \"drop\") %&gt;%\n    rename(Group = !!sym(group_col), RY = runoff_year) %&gt;%\n    arrange(Group, RY)\n\n  percentiles_wy &lt;- seasonal_wy %&gt;%\n    group_by(Group) %&gt;%\n    mutate(\n      `Apr-Sep pct` = if_else(\n        is.na(`Apr-Sep`),\n        NA_real_,\n        round(dplyr::percent_rank(`Apr-Sep`) * 100, 1)\n      ),\n      `Oct-Mar pct` = if_else(\n        is.na(`Oct-Mar`),\n        NA_real_,\n        round(dplyr::percent_rank(`Oct-Mar`) * 100, 1)\n      )\n    ) %&gt;%\n    ungroup() %&gt;%\n    filter(WY == target_year) %&gt;%\n    select(Group, WY, `Apr-Sep`, `Apr-Sep pct`, `Oct-Mar`, `Oct-Mar pct`)\n\n  percentiles_ry &lt;- runoff_ry %&gt;%\n    group_by(Group) %&gt;%\n    mutate(\n      `Apr-Mar pct` = if_else(\n        is.na(`Apr-Mar`),\n        NA_real_,\n        round(dplyr::percent_rank(`Apr-Mar`) * 100, 1)\n      )\n    ) %&gt;%\n    ungroup() %&gt;%\n    filter(RY == target_year) %&gt;%\n    select(Group, RY, `Apr-Mar`, `Apr-Mar pct`)\n\n  list(\n    seasonal_wy = seasonal_wy,\n    runoff_ry = runoff_ry,\n    percentiles_wy = percentiles_wy,\n    percentiles_ry = percentiles_ry\n  )\n}"
  },
  {
    "objectID": "index.html#linked-wells-qaqc",
    "href": "index.html#linked-wells-qaqc",
    "title": "Flow Data",
    "section": "Linked Wells QA/QC",
    "text": "Linked Wells QA/QC\nLinked-well pumping plots from the on/off management program support visual QA/QC of annual totals.\ntm2 &lt;- totals_means\n\nlinked_wells_sites &lt;- data.frame(\n  Site = rep(\n    c(\n      \"BP1\", \"BP2\", \"BP3\", \"BP4\",\n      \"LW1\", \"LW2\", \"LW3\",\n      \"TA3\", \"TA4\", \"TA5\", \"TA6\",\n      \"TS1\", \"TS2\", \"TS3\", \"TS4\",\n      \"IO1\", \"IO2\",\n      \"SS1\", \"SS2\", \"SS3\", \"SS4\",\n      \"BG2\"\n    ),\n    times = c(4, 4, 4, 1, 4, 4, 5, 4, 2, 1, 2, 1, 1, 3, 2, 3, 1, 3, 3, 2, 2, 4)\n  ),\n  Linked_Well = c(\n    \"W210\", \"W378\", \"W379\", \"W389\",   # BP1\n    \"W220\", \"W229\", \"W374\", \"W375\",   # BP2\n    \"W222\", \"W223\", \"W231\", \"W232\",   # BP3\n    \"W331\",                            # BP4\n    \"W247\", \"W248\", \"W249\", \"W398\",   # LW1\n    \"W236\", \"W239\", \"W243\", \"W244\",   # LW2\n    \"W240\", \"W241\", \"W399\", \"W376\", \"W377\", # LW3\n    \"W106\", \"W110\", \"W111\", \"W114\",   # TA3\n    \"W342\", \"W347\",                   # TA4\n    \"W349\",                           # TA5\n    \"W109\", \"W370\",                   # TA6\n    \"W159\",                           # TS1\n    \"W155\",                           # TS2\n    \"W103\", \"W104\", \"W382\",           # TS3\n    \"W380\", \"W381\",                   # TS4\n    \"W061\", \"W391\", \"W400\",           # IO1\n    \"W063\",                           # IO2\n    \"W069\", \"W392\", \"W393\",           # SS1\n    \"W074\", \"W394\", \"W395\",           # SS2\n    \"W092\", \"W396\",                   # SS3\n    \"W075\", \"W345\",                   # SS4\n    \"W076\", \"W403\", \"W343\", \"W348\"    # BG2\n  )\n)\n\nwellfield_sites &lt;- tibble(\n  Wellfield = c(\n    \"Laws\",\n    \"Big Pine\",\n    \"Taboose/Aberdeen\",\n    \"Thibaut/Sawmill\",\n    \"Independence/Oak\",\n    \"Symmes/Shepherd\",\n    \"Bairs/Georges\"\n  ),\n  Site = I(list(\n    c(\"LW1\", \"LW2\", \"LW3\"),\n    c(\"BP1\", \"BP2\", \"BP3\", \"BP4\"),\n    c(\"TA3\", \"TA4\", \"TA5\", \"TA6\"),\n    c(\"TS1\", \"TS2\", \"TS3\", \"TS4\"),\n    c(\"IO1\", \"IO2\"),\n    c(\"SS1\", \"SS2\", \"SS3\", \"SS4\"),\n    c(\"BG2\")\n  ))\n) %&gt;%\n  unnest(Site)\n\nsite_map &lt;- linked_wells_sites %&gt;% select(Linked_Well, Site)\nwellfield_map &lt;- linked_wells_sites %&gt;%\n  left_join(wellfield_sites, by = \"Site\") %&gt;%\n  select(Linked_Well, Wellfield)\n\nseasonal_by_site &lt;- compute_linked_seasonal(tm2, linked_wells_sites, site_map, \"Site\", target_year = wy_year)\nseasonal_by_wellfield &lt;- compute_linked_seasonal(tm2, linked_wells_sites, wellfield_map, \"Wellfield\", target_year = wy_year)\nSeasonal totals use water year (WY, Oct–Sep end year) for Apr–Sep and Oct–Mar. Runoff totals use runoff year (RY, Apr–Mar start year). Example: RY2025 = Apr 2025–Mar 2026.\nSeasonal pumping totals by site (water year Oct-Sep)\nDT::datatable(\n  seasonal_by_site$seasonal_wy,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE)\n)\nRunoff year totals by site (Apr-Mar)\nDT::datatable(\n  seasonal_by_site$runoff_ry,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE)\n)\nWY2025 percentiles by site (water year Oct-Sep)\nPercentiles are calculated within each site using the historical distribution of Apr–Sep totals (and separately Oct–Mar totals). WY2025 percentiles therefore rank the 2025 six‑month total against all prior years for that site.\nDT::datatable(\n  seasonal_by_site$percentiles_wy,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE)\n)\nRY2025 percentiles by site (runoff year Apr-Mar)\nDT::datatable(\n  seasonal_by_site$percentiles_ry,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE)\n)\nSeasonal pumping totals by wellfield (water year Oct-Sep)\nDT::datatable(\n  seasonal_by_wellfield$seasonal_wy,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE)\n)\nRunoff year totals by wellfield (Apr-Mar)\nDT::datatable(\n  seasonal_by_wellfield$runoff_ry,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE)\n)\nWY2025 percentiles by wellfield (water year Oct-Sep)\nPercentiles are calculated within each wellfield using the historical distribution of Apr–Sep totals (and separately Oct–Mar totals). WY2025 percentiles therefore rank the 2025 six‑month total against all prior years for that wellfield.\nDT::datatable(\n  seasonal_by_wellfield$percentiles_wy,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE)\n)\nRY2025 percentiles by wellfield (runoff year Apr-Mar)\nDT::datatable(\n  seasonal_by_wellfield$percentiles_ry,\n  options = list(pageLength = 10, lengthChange = TRUE, scrollX = TRUE)\n)\nLaws Monitoring Site #1 (LW1)\n{r, fig.height=3} plot_linked_wells(tm2, \"LW1\", linked_wells_sites)\nLaws Monitoring Site #2 (LW2)\n{r, fig.height=3} plot_linked_wells(tm2, \"LW2\", linked_wells_sites)\nLaws Monitoring Site #3 (LW3)\n{r, fig.height=3} plot_linked_wells(tm2, \"LW3\", linked_wells_sites)\nLaws Wellfield Total Pumping\n{r, fig.height=3} plot_wellfield_total(   tm2,   field_sites = c(\"LW1\", \"LW2\", \"LW3\"),   linked_wells_sites = linked_wells_sites,   title = \"Laws Wellfield Total Pumping\" )\nBig Pine Monitoring Site #1 (BP1)\n{r, fig.height=3} plot_linked_wells(tm2, \"BP1\", linked_wells_sites)\nBig Pine Monitoring Site #2 (BP2)\n{r, fig.height=3} plot_linked_wells(tm2, \"BP2\", linked_wells_sites)\nBig Pine Monitoring Site #3 (BP3)\n{r, fig.height=3} plot_linked_wells(tm2, \"BP3\", linked_wells_sites)\nBig Pine Monitoring Site #4 (BP4)\n{r, fig.height=3} plot_linked_wells_single(tm2, \"BP4\", linked_wells_sites)\nExempt Wells - Fish Hatchery and 218, 219\n```{r , fig.height= 3} #| label: fig-hatchery-exempt #| fig-cap: “hatchery wells 330/332 and exempt wells 218/219”\nlinked_wells &lt;- c(“W218”,“W219”,“W330”,“W332”)\nDF &lt;- tm2 %&gt;% filter(staid %in% linked_wells) %&gt;% mutate(read = if_else(read == -777, 0, read)) %&gt;% group_by(roy, staid) %&gt;% summarise(total_pumping = sum(read, na.rm = TRUE), .groups = “drop”) %&gt;% mutate(roy2 = make_date(roy, 4, 1))\nDF &lt;- pad_series_bounds(DF, “roy2”, “staid”, months_start = 6, months_end = 18)\nData &lt;- do.call(merge, lapply(split(DF, DFstaid), tozoo))\nyear_totals_exempt &lt;- DF %&gt;%\n  group_by(roy2) %&gt;%\n  summarise(total_pumping = sum(total_pumping, na.rm = TRUE), .groups = \"drop\")\ny_max_exempt &lt;- max(year_totals_exempttotal_pumping, na.rm = TRUE)\nplot_exempt &lt;- Data %&gt;% dygraph(group = “a”) %&gt;% dyStackedBarGroup(c(“W218”,“W219”,“W330”,“W332”)) %&gt;% dyBarChart() %&gt;% dyAxis(“y”, label = “Total Annual Pumping (AF)”, axisLabelWidth = 70)\nif (is.finite(y_max_exempt)) { plot_exempt &lt;- plot_exempt %&gt;% dyAxis(“y”, valueRange = c(0, y_max_exempt * 1.05)) }\nplot_exempt\n\n### Big Pine Pumping Totals\n\n```{r}\n#| label: bppumping\n#| fig-cap: \"Big Pine Wellfield Pumping\"\n\nlinked_wells &lt;- c(\"W210\",\"W378\",\"W379\",\"W389\",\"W220\",\"W229\",\"W374\",\"W375\",\"W222\",\"W223\",\"W231\",\"W232\",\"W331\",\"W218\",\"W219\",\"W330\",\"W332\")\n\nDF &lt;- tm2 %&gt;%\n  filter(staid %in% linked_wells) %&gt;%\n  mutate(read = if_else(read == -777, 0, read)) %&gt;%\n  group_by(roy, staid) %&gt;%\n  summarise(total_pumping = sum(read, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  mutate(roy2 = make_date(roy, 4, 1))\n\nDF &lt;- pad_series_bounds(DF, \"roy2\", \"staid\", months_start = 6, months_end = 18)\n\nData &lt;- do.call(merge, lapply(split(DF, DF$staid), tozoo))\nyear_totals_bp &lt;- DF %&gt;%\n  group_by(roy2) %&gt;%\n  summarise(total_pumping = sum(total_pumping, na.rm = TRUE), .groups = \"drop\")\ny_max_bp &lt;- max(year_totals_bp$total_pumping, na.rm = TRUE)\n\nplot_bp &lt;- Data %&gt;% dygraph(group = \"a\") %&gt;%\n  dyStackedBarGroup(c(\"W210\",\"W378\",\"W379\",\"W389\",\"W220\",\"W229\",\"W374\",\"W375\",\"W222\",\"W223\",\"W231\",\"W232\",\"W331\",\"W218\",\"W219\",\"W330\",\"W332\")) %&gt;%\n  dyBarChart() %&gt;%\n  dyAxis(\"y\", label = \"Total Annual Pumping (AF)\", axisLabelWidth = 70)\n\nif (is.finite(y_max_bp)) {\n  plot_bp &lt;- plot_bp %&gt;% dyAxis(\"y\", valueRange = c(0, y_max_bp * 1.05))\n}\n\nplot_bp\n\nTaboose/Aberdeen Monitoring Site #3 (TA3)\n{r, fig.height=3} plot_linked_wells(tm2, \"TA3\", linked_wells_sites)\nTaboose/Aberdeen Monitoring Site #4 (TA4)\n{r, fig.height=3} plot_linked_wells(tm2, \"TA4\", linked_wells_sites)\nTaboose/Aberdeen Monitoring Site #5 (TA5)\n{r, fig.height=3} plot_linked_wells_single(tm2, \"TA5\", linked_wells_sites)\nTaboose/Aberdeen Monitoring Site #6 (TA6)\n{r, fig.height=3} plot_linked_wells(tm2, \"TA6\", linked_wells_sites)\nTaboose/Aberdeen Wellfield Total Pumping\n{r, fig.height=3} plot_wellfield_total(   tm2,   field_sites = c(\"TA3\", \"TA4\", \"TA5\", \"TA6\"),   linked_wells_sites = linked_wells_sites,   title = \"Taboose/Aberdeen Wellfield Total Pumping\" )\nThibaut/Sawmill Monitoring Site #1 (TS1)\n{r, fig.height=3} plot_linked_wells_single(tm2, \"TS1\", linked_wells_sites)\nThibaut/Sawmill Monitoring Site #2 (TS2)\n{r, fig.height=3} plot_linked_wells_single(tm2, \"TS2\", linked_wells_sites)\nThibaut/Sawmill Monitoring Site #3 (TS3)\n{r, fig.height=3} plot_linked_wells(tm2, \"TS3\", linked_wells_sites)\nThibaut/Sawmill Monitoring Site #4 (TS4)\n{r, fig.height=3} plot_linked_wells(tm2, \"TS4\", linked_wells_sites)\nThibaut/Sawmill Wellfield Total Pumping\n{r, fig.height=3} plot_wellfield_total(   tm2,   field_sites = c(\"TS1\", \"TS2\", \"TS3\", \"TS4\"),   linked_wells_sites = linked_wells_sites,   title = \"Thibaut/Sawmill Wellfield Total Pumping\" )\nIndependence/Oak Monitoring Site #1 (IO1)\n{r, fig.height=3} plot_linked_wells(tm2, \"IO1\", linked_wells_sites)\nIndependence/Oak Monitoring Site #2 (IO2)\n{r, fig.height=3} plot_linked_wells_single(tm2, \"IO2\", linked_wells_sites)\nIndependence/Oak Wellfield Total Pumping\n{r, fig.height=3} plot_wellfield_total(   tm2,   field_sites = c(\"IO1\", \"IO2\"),   linked_wells_sites = linked_wells_sites,   title = \"Independence/Oak Wellfield Total Pumping\" )\nSymmes/Shepherd Monitoring Site #1 (SS1)\n{r, fig.height=3} plot_linked_wells(tm2, \"SS1\", linked_wells_sites)\nSymmes/Shepherd Monitoring Site #2 (SS2)\n{r, fig.height=3} plot_linked_wells(tm2, \"SS2\", linked_wells_sites)\nSymmes/Shepherd Monitoring Site #3 (SS3)\n{r, fig.height=3} plot_linked_wells(tm2, \"SS3\", linked_wells_sites)\nSymmes/Shepherd Monitoring Site #4 (SS4)\n{r, fig.height=3} plot_linked_wells(tm2, \"SS4\", linked_wells_sites)\nSymmes/Shepherd Wellfield Total Pumping\n{r, fig.height=3} plot_wellfield_total(   tm2,   field_sites = c(\"SS1\", \"SS2\", \"SS3\", \"SS4\"),   linked_wells_sites = linked_wells_sites,   title = \"Symmes/Shepherd Wellfield Total Pumping\" )\nBairs/Georges Monitoring Site #2 (BG2)\n{r, fig.height=3} plot_linked_wells(tm2, \"BG2\", linked_wells_sites)\nBairs/Georges Wellfield Total Pumping\n{r, fig.height=3} plot_wellfield_total(   tm2,   field_sites = c(\"BG2\"),   linked_wells_sites = linked_wells_sites,   title = \"Bairs/Georges Wellfield Total Pumping\" )"
  }
]